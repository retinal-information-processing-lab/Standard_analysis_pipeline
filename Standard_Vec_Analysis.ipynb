{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "998db494",
   "metadata": {},
   "source": [
    "# Vec File Based Analysis\n",
    "\n",
    "This notebook allows you to perform a simple \"classic analysis of raster and psth of your recording using you vec file as reference for sequences. Your vec file last column must contain the trigger sequence key. This shold have the following shape : \"1\" + \"any number you want\" + \"Two digit repetition number\". Repetition number don't need to be sorted. They will be analysed and stacked in the raster in their order of appearance in the vec file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46407c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import params\n",
    "from utils import *\n",
    "from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "\n",
    "import math\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# For clustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy as sc\n",
    "from sklearn.decomposition import SparsePCA\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f03ef1",
   "metadata": {},
   "source": [
    "### Load recording data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293162c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Variables\n",
    "    \n",
    "    DO NOT CHANGE VALUES HERE UNLESS DEBUG/SPECIFIC USE\n",
    "    \n",
    "    All the variables used in this part of the cell should always refere to your 'params.py' file\n",
    "    unless you want to manually change them only for this run (i.e. debugging). \n",
    "    You may have to add those variable into the function you want to adapt as only the minimal \n",
    "    amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "recording_names = params.recording_names\n",
    "\n",
    "#Experiment name\n",
    "exp = params.exp\n",
    "\n",
    "#Analysis output directory\n",
    "output_directory=params.output_directory\n",
    "\n",
    "#Sampling rate of the mea\n",
    "fs = params.fs  \n",
    "\n",
    "#Trigger directory\n",
    "triggers_directory= params.triggers_directory\n",
    "\n",
    "#Vec files drectory\n",
    "vec_directory = os.path.join(params.root,'VEC_Files')\n",
    "\n",
    "#List all vec files in vec files directory\n",
    "available_vec = os.listdir(os.path.normpath(vec_directory))\n",
    "\n",
    "\"\"\"\n",
    "    Input\n",
    "\"\"\"\n",
    "\n",
    "cells_to_skip = []  ### LOAD HERE CELLS TO SKIP IF YOU WANT TO SELECT SPECIFICALY SOME OF THEM\n",
    "\n",
    "\n",
    "#Find rec triggers\n",
    "print(*['{} : {}'.format(i,recording_name) for i, recording_name in enumerate(recording_names)], sep=\"\\n\")\n",
    "recording_number = int(input(\"\\nSelect recording : \"))\n",
    "rec = recording_names[recording_number]\n",
    "print(f\"\\nSelected recording : {rec} \\n\")\n",
    "\n",
    "analysis_directory = os.path.normpath(os.path.join(output_directory,r'Vec_Analysis_rec_{}'.format(recording_number)))\n",
    "if not os.path.isdir(analysis_directory): os.makedirs(analysis_directory)\n",
    "\n",
    "#Find stim vec file\n",
    "print(*['{} : {}'.format(i,vec_file) for i, vec_file in enumerate(available_vec)], sep=\"\\n\")\n",
    "vec_number = int(input(\"\\nSelect stimulus file : \"))\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "\n",
    "#Load vec file\n",
    "vec = np.loadtxt(os.path.join(vec_directory,available_vec[vec_number]))[1:,:]  #Remove first line as it is not a trigger\n",
    "print(f\"\\nSelected vec file : {available_vec[vec_number]}\\n\")\n",
    "print(f\"Vec file length : {vec.shape[0]}\")\n",
    "\n",
    "#load triggers\n",
    "trig_data = load_obj(os.path.normpath(os.path.join(triggers_directory,'{}_{}_triggers.pkl'.format(exp,rec))))\n",
    "trig_indices = trig_data['indices']\n",
    "stim_onsets = trig_data['indices']/fs\n",
    "print(f\"Total triggers number : {len(stim_onsets)}\")\n",
    "print(f\"Triggers type loaded : {trig_data['trigger_type']}\")\n",
    "\n",
    "spike_trains=load_obj(os.path.join(output_directory, r'{}_fullexp_neurons_data.pkl'.format(exp)))\n",
    "\n",
    "cells=list(spike_trains.keys())\n",
    "spike_times={}\n",
    "for cell in cells:\n",
    "    if cell in cells_to_skip: continue\n",
    "    spike_times[cell] = (spike_trains[cell][rec])\n",
    "    \n",
    "print('Total : {} neurons loaded \\n\\nClusters id :\\n{}\\n'.format(len(spike_trains.keys()),cells))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc6167",
   "metadata": {},
   "source": [
    "### Compute raster and psth for all sequences types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f23c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Input\n",
    "\"\"\"\n",
    "\n",
    "n_bin=40          # binning for the psth, default = 40\n",
    "n_bin ='relative' # if n_bin = \"relative\", n_bin = sqrt(nb of spikes in the raster)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Variables\n",
    "\"\"\"\n",
    "\n",
    "dict_name = f'{rec}_dict.pkl'\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "\n",
    "#Check if computing is needed first\n",
    "if not os.path.exists(os.path.join(analysis_directory, dict_name)) or (str(input('Trigers already extracted previously. Write again files files? Type Yes to do so :\\n')) in [\"Y\", \"y\", \"yes\", \"Yes\"]):\n",
    "    print(\"Splitting spikes into sequences for each cluster...\")\n",
    "    rec_dict = {}\n",
    "    sorted_data = {}\n",
    "    trig_seq  = get_sequences_triggers(stim_onsets, vec) # Create a dictionnary with sequence keys including repetion number\n",
    "                                                         # as key and a list of all the triggers in this repetition seq\n",
    "                                                         # {\"rep_seq_key\" : [float]}\n",
    "    for i in tqdm(cells):\n",
    "\n",
    "        #Process\n",
    "        rec_dict[i]={}\n",
    "        spike_seq = get_spikes_sequences(spike_times[i], trig_seq) # Create a dictionnary for each cluster with sequence keys including repetion number\n",
    "                                                                   # as key and a list of all the spikes in this repetition seq \n",
    "                                                                   # {\"rep_seq_key\" : [float]}\n",
    "                \n",
    "        raster    = spikeseq2raster(spike_seq, trig_seq)           # Create a dictionnary for each cluster with sequence types keys \n",
    "                                                                   # as key and a list of all the repetition of this sequence type (raster of the sequence type) \n",
    "                                                                   # {\"seq_type_key\" : [np.arrays]}\n",
    "\n",
    "        psth      = spikeseq2psth(raster, trig_seq, n_bin=n_bin)   # Create a dictionnary for each cluster with sequence types keys \n",
    "                                                                   # as key and a binning of the raster \n",
    "                                                                   # {\"seq_type_key\" : np.array (len(n_bin))}\n",
    "                \n",
    "        #Cluster all data in a dict {Cell_id : {\"seq_type_key\": {'raster': [np.arrays]; 'psth':np.array (len(n_bin)) }  }   }\n",
    "        sorted_data[i] = spike_seq\n",
    "        for key in raster.keys():\n",
    "            if key=='': continue\n",
    "            rec_dict[i][key]={}\n",
    "            rec_dict[i][key]['raster']   = raster[key]\n",
    "            rec_dict[i][key]['psth']     = psth[key]\n",
    "            \n",
    "            #Add the necessary info for plotting about the seq length and triggers taking the repetition number 0 of this seqence type\n",
    "            rec_dict[i][key]['triggers'] = {\n",
    "                'start':trig_seq['1'+key+'00'][0], \n",
    "                'end':trig_seq['1'+key+'00'][-1], \n",
    "                'rng':(0, trig_seq['1'+key+'00'][-1]-trig_seq['1'+key+'00'][0] + np.mean(np.diff(trig_seq['1'+key+'00']))),\n",
    "                }   \n",
    "            \n",
    "    # Saving all dict generated\n",
    "    print(\"Saving...\")\n",
    "    save_obj(rec_dict, os.path.join(analysis_directory, dict_name))\n",
    "    save_obj(trig_seq, os.path.join(analysis_directory, f'{rec}_Sorted_triggers.pkl'))\n",
    "    save_obj(sorted_data, os.path.join(analysis_directory, f'{rec}_Sorted_Spikes.pkl'))\n",
    "else:\n",
    "    print(f\"Dictionnary loaded from : \\n{os.path.join(analysis_directory, dict_name)}\")\n",
    "    rec_dict = load_obj(os.path.join(analysis_directory, dict_name))\n",
    "    \n",
    "del sorted_data \n",
    "print(\"----- Done -----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941d3bd7",
   "metadata": {},
   "source": [
    "### Plot Raster and PSTH for all conditions (cell x sequence types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b892bf6",
   "metadata": {},
   "source": [
    "Can take a lot of time (about 10s per condition). You may want to load the rec_dict in an other notebook to do your own plotting for it to be more efficient !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da25187e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clusters_as_folder = True   #If true, creates a folder per cell and save there a plot of this cell for each sequence\n",
    "                            #else, creates a folder per sequence and save there a plot of this seq for each cell\n",
    "\n",
    "color =\"#B85A8F\"     #Plotting color\n",
    "\n",
    "if clusters_as_folder:\n",
    "    dict_to_plot = rec_dict\n",
    "    element = \"Cell\"\n",
    "    scd_element = \"Sequence\"\n",
    "\n",
    "else:\n",
    "    dict_to_plot = reshape_dict(rec_dict)  #Reverse dict in the case of saving per sequence\n",
    "    element = \"Sequence\"\n",
    "    scd_element = \"Cell\"\n",
    "\n",
    "for elt in tqdm(dict_to_plot.keys()):\n",
    "    item_directory = os.path.normpath(os.path.join(analysis_directory,f'{element}_{elt}')) #Saving folder for this cell or sequence\n",
    "    if not os.path.isdir(item_directory): os.makedirs(item_directory)\n",
    "    \n",
    "    for scd_elt in dict_to_plot[elt].keys():\n",
    "        if os.path.isfile(os.path.join(item_directory,f'{scd_element}_{scd_elt}.png')): continue  #Check if need to plot or not\n",
    "        \n",
    "        # New figure\n",
    "        fig, axs = plt.subplots(nrows = 2,ncols = 1, sharex=True, gridspec_kw={'height_ratios': [3, 1]}, figsize=(10,10))\n",
    "                \n",
    "        #Plot the rasters\n",
    "        ax_rast = axs[0]\n",
    "        ax_rast.eventplot(dict_to_plot[elt][scd_elt][\"raster\"], color=color)\n",
    "        ax_rast.set(title = \"Raster plot\", ylabel='N Repetitions')\n",
    "            \n",
    "        #Plot the psth\n",
    "        ax_psth = axs[1]\n",
    "        y    = dict_to_plot[elt][scd_elt][\"psth\"]\n",
    "        rng  = dict_to_plot[elt][scd_elt]['triggers']['rng']\n",
    "        y    = y*(len(y)/(rng[1]-rng[0]))   #Turning number of spikes into firing rate \n",
    "        ysmooth = smooth(y,.4)\n",
    "        \n",
    "        x=np.linspace(rng[0],rng[1],len(y))\n",
    "        ax_psth.fill_between(x, ysmooth,0,alpha=1, color=color)\n",
    "        ax_psth.set(xlabel='Time in sec', ylabel='Firing rate (spikes/s)')\n",
    "        ax_psth.set_ylim(bottom=-0.1, top=max(1, max(ysmooth)))\n",
    "\n",
    "        #Finish the plot and save\n",
    "        plt.suptitle(f'{scd_element}_{scd_elt}')\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "        plt.savefig(os.path.join(item_directory,f'{scd_element}_{scd_elt}.png'))\n",
    "        plt.close(fig)\n",
    "        del fig\n",
    "        gc.collect() #Just in case..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
