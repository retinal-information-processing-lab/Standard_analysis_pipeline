{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad00f68f",
   "metadata": {},
   "source": [
    "# <center>Preprocessing Data Analysis</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84d3bb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing spike interface, this may take a while...\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "\n",
    "print(\"Importing spike interface, this may take a while...\")\n",
    "import spikeinterface.full as si\n",
    "print(\"Done...\")\n",
    "import scipy\n",
    "\n",
    "import probeinterface as pi\n",
    "from probeinterface.plotting import plot_probe_group, plot_probe\n",
    "\n",
    "# Load probe\n",
    "probe = pi.read_prb('ressources/mea_256_30-8iR-ITO.prb')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('qt5agg')\n",
    "\n",
    "from utils import *         # Local file containing all the functions that we need\n",
    "import params               # Parameters file. You should tune it for your own experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de83b9",
   "metadata": {},
   "source": [
    "# Run this before the sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79df1167",
   "metadata": {},
   "source": [
    "### Cell 1: Create Symbolic links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a206117",
   "metadata": {},
   "source": [
    "As spyking circus requires a specific file format, we create here symbolic links to the raw recording file with the right Spyking circus format. This cell contains important variable for the rest of the notebook. You should check stim duration as sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4158816f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered raws have been found. Use these for symbolic links ? type Yes :Y\n",
      "Links created from files in : /home/guiglaz/Documents/Pipeline_Git_Repo/RAW_filtered\n",
      "\n",
      "Number of recordings: 22\n",
      "\n",
      "\n",
      "Check that recordings lengths are consistent with recording names\n",
      "\n",
      "0 : \t00_Checkerboard_30ND50%_20pix30checks_30Hz \t---> link  already existed\n",
      "\tVisual Recording --> 55 minutes \n",
      "\n",
      "1 : \t01_Checkerboard_30ND50%_16pix40checks_30Hz \t---> link  already existed\n",
      "\tVisual Recording --> 24 minutes \n",
      "\n",
      "2 : \t02_DG_30ND50%_2sT_50Hz \t---> link  already existed\n",
      "\tVisual Recording --> 6 minutes \n",
      "\n",
      "3 : \t03_Chirp_20reps_30ND50%_50Hz \t---> link  already existed\n",
      "\tVisual Recording --> 11 minutes \n",
      "\n",
      "4 : \t04_Flicker_BeforeDrugs_30ND50%_1Hz \t---> link  already existed\n",
      "\tVisual Recording --> 5 minutes \n",
      "\n",
      "5 : \t05_VDH_Synchro+MultiSpots(bright)_N8_Z(-35)_30ND50%_40Hz \t---> link  already existed\n",
      "\tHOLO RECORDING --> 115 minutes \n",
      "\n",
      "6 : \t06_VDH_Synchro_N10_Z(-35)_30ND50%_40Hz \t---> link  already existed\n",
      "\tHOLO RECORDING --> 16 minutes \n",
      "\n",
      "7 : \t07_Flicker_LAP4+ACET_t+10_30ND50%_1Hz \t---> link  already existed\n",
      "\tVisual Recording --> 4 minutes \n",
      "\n",
      "8 : \t08_HoloStim1_LAP4+ACET_N8_Z(-35) \t---> link  already existed\n",
      "\tHOLO RECORDING --> 3 minutes \n",
      "\n",
      "9 : \t09_HoloStim1_LAP4+ACET_N15_Z(-30) \t---> link  already existed\n",
      "\tHOLO RECORDING --> 5 minutes \n",
      "\n",
      "10 : \t10_OptoStim1_LAP4+ACET_15ND50%_1Hz \t---> link  already existed\n",
      "\tVisual Recording --> 5 minutes \n",
      "\n",
      "11 : \t11_OptoStim1_LAP4+ACET_5ND50%_1Hz \t---> link  already existed\n",
      "\tVisual Recording --> 5 minutes \n",
      "\n",
      "12 : \t12_HoloStim2_GRF_t30_N15_Z(-30) \t---> link  already existed\n",
      "\tHOLO RECORDING --> 5 minutes \n",
      "\n",
      "13 : \t13_OptoStim2_GRF_t35_15ND50%_1Hz \t---> link  already existed\n",
      "\tVisual Recording --> 5 minutes \n",
      "\n",
      "14 : \t14_OptoStim2_GRF_t40_5ND50%_1Hz \t---> link  already existed\n",
      "\tVisual Recording --> 3 minutes \n",
      "\n",
      "15 : \t15_HoloStim3_SR95531_t30_N15_Z(-30) \t---> link  already existed\n",
      "\tHOLO RECORDING --> 5 minutes \n",
      "\n",
      "16 : \t16_OptoStim3_SR95531_t35_15ND50%_1Hz \t---> link  already existed\n",
      "\tVisual Recording --> 5 minutes \n",
      "\n",
      "17 : \t17_OptoStim3_SR95531_t40_5ND50%_1Hz \t---> link  already existed\n",
      "\tVisual Recording --> 4 minutes \n",
      "\n",
      "18 : \t18_HoloStim3_18BG_t5_N15_Z(-30) \t---> link  already existed\n",
      "\tHOLO RECORDING --> 5 minutes \n",
      "\n",
      "19 : \t19_OptoStim3_18BG_t10_15ND50%_1Hz \t---> link  already existed\n",
      "\tVisual Recording --> 4 minutes \n",
      "\n",
      "20 : \t20_OptoStim3_18BG_t15_5ND50%_1Hz \t---> link  already existed\n",
      "\tVisual Recording --> 4 minutes \n",
      "\n",
      "21 : \t21_HoloStim3_18BG_t20_N15_Z(-30) \t---> link  already existed\n",
      "\tHOLO RECORDING --> 5 minutes \n",
      "\n",
      "\n",
      "\t\t\t------ End Of Cell ------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Inputs\n",
    "\"\"\"\n",
    "\n",
    "#Duration at the begining of the recording to check recording type (default 10s)\n",
    "time = 40   #Increase until all your holographic recordings are detected as such\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "    Variables\n",
    "    \n",
    "    DO NOT CHANGE VALUES HERE UNLESS DEBUG/SPECIFIC USE\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "#Path to your sorting directory where symbolic links should be created\n",
    "symbolic_link_directory = params.symbolic_link_directory\n",
    "\n",
    "#Link to the actual raw files from the recording listed in the input_file\n",
    "recording_directory     = params.recording_directory\n",
    "\n",
    "#Loading raw recording files names\n",
    "recording_names = params.recording_names\n",
    "\n",
    "#Type of data in your raws (float32, uint16, int16, ...)\n",
    "dtype = params.dtype\n",
    "\n",
    "#Sampling frequency of the mea\n",
    "fs = params.fs\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "\n",
    "#Paths to which create recording links (useful if raws needs to be filtered before sorting)\n",
    "if os.path.isdir(params.raw_filtered_directory) and input(\"Filtered raws have been found. Use these for symbolic links ? type Yes :\") in [\"YES\", \"yes\", \"Yes\", \"Y\", \"y\"]:\n",
    "    link_recording_directory     = params.raw_filtered_directory\n",
    "    link_recording_names         = params.find_files(link_recording_directory) \n",
    "else :\n",
    "    link_recording_directory     = recording_directory\n",
    "    link_recording_names         = recording_names\n",
    "    \n",
    "    \n",
    "print(f\"Links created from files in : {link_recording_directory}\\n\")\n",
    "link_names, previously_existing = create_symlinks([rec+r'.raw' for rec in link_recording_names], symbolic_link_directory, link_recording_directory, print_warning=False)\n",
    "\n",
    "recording_names = [rec.replace('.raw','') for rec in recording_names]\n",
    "rec_it = recording_names[:]+['end']\n",
    "print('Number of recordings: {}\\n'.format(len(recording_names)))\n",
    "\n",
    "#getting onset for next prints\n",
    "onsets = {}\n",
    "onsets = recording_onsets(recording_names, path = recording_directory)\n",
    "\n",
    "\n",
    "#Opening files\n",
    "print('\\nCheck that recordings lengths are consistent with recording names\\n') \n",
    "\n",
    "for i in range(len(rec_it)-1):\n",
    "    is_holo = [\"HOLO RECORDING\" if is_holographic_rec(os.path.join(recording_directory,recording_names[i]+r\".raw\"), dtype=dtype, probe_size = time*params.fs) else \"Visual Recording\"]\n",
    "    print(\"{} : \\t{} \\t---> link {}\".format(i,rec_it[i], [previously_existing[i] if previously_existing[i] == ' already existed' else \"created\"][0]))\n",
    "    print(\"\\t{} --> {} minutes \\n\".format(is_holo[0],\n",
    "                                                         int((onsets[rec_it[i+1]]-onsets[rec_it[i]])/fs/60)))      \n",
    "\n",
    "\"\"\"Output :\n",
    "\n",
    "Var :\n",
    "recordings_names : Ordered list of stimuli names played during experiment and their detected types\n",
    "\"\"\"   \n",
    "\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e0ebf",
   "metadata": {},
   "source": [
    "### Cell 2 : Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756ad360",
   "metadata": {},
   "source": [
    "#### <center>REQUIRES CELL 1 RUN</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f4b44",
   "metadata": {},
   "source": [
    "Sanity checks of symlinks comparing onsets recorded from raw files and onsets recorded from symlinks. If both plots are identical, it is likely that links point to the right recording files. Otherwise, links are pointing to the wrong files. You may want to check your params.py file for a wrong directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d64f2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Make sure both plots are identical\n",
      "\n",
      "\t\t\t---symlinks--- End Of Cell ------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Variables\n",
    "    \n",
    "    DO NOT CHANGE VALUES HERE UNLESS DEBUG/SPECIFIC USE\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "#Link to the folder where spiking circus will look for the symbolic links \"recording_0i.raw\"\n",
    "symbolic_link_directory = params.symbolic_link_directory\n",
    "\n",
    "#Link to the actual raw files from the recording listed in the input_file\n",
    "recording_directory     = params.recording_directory\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "\n",
    "rec_onsets  = recording_onsets(recording_names, path = recording_directory)\n",
    "\n",
    "link_onsets = recording_onsets(link_names, path = symbolic_link_directory)\n",
    "\n",
    "\"\"\"\n",
    "    Ploting\n",
    "\"\"\"\n",
    "print(\"\\nMake sure both plots are identical\")\n",
    "plt.close('all')\n",
    "fig = plt.figure(\"Links Sanity Check\", figsize=(10,6))\n",
    "\n",
    "# LEFT PLOT\n",
    "ticks=[]\n",
    "plt.subplot(1,2,1)\n",
    "for rec in recording_names:\n",
    "    plt.axhline(rec_onsets[rec]/params.fs/60)\n",
    "    ticks.append(rec_onsets[rec]/params.fs/60)\n",
    "plt.axhline(rec_onsets['end']/params.fs/60)\n",
    "ticks.append(rec_onsets['end']/params.fs/60)\n",
    "\n",
    "plt.yticks(ticks)\n",
    "plt.title('Recordings onsets')\n",
    "plt.ylabel('Minutes')\n",
    "\n",
    "# RIGHT PLOT\n",
    "ticks=[]\n",
    "plt.subplot(1,2,2)\n",
    "for rec in link_names:\n",
    "    plt.axhline(link_onsets[rec]/params.fs/60)\n",
    "    ticks.append(link_onsets[rec]/params.fs/60)\n",
    "plt.axhline(link_onsets['end']/params.fs/60)\n",
    "ticks.append(link_onsets['end']/params.fs/60)\n",
    "plt.yticks(ticks)\n",
    "plt.title('Links onsets')\n",
    "plt.ylabel('Minutes')\n",
    "\n",
    "plt.show(block = False)\n",
    "\n",
    "print('\\n\\t\\t\\t---symlinks--- End Of Cell ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ecdb2a",
   "metadata": {},
   "source": [
    "### Cell 3 : Extract the triggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b9255e",
   "metadata": {},
   "source": [
    "#### <center>REQUIRES CELL 1 RUN</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb53ca0",
   "metadata": {},
   "source": [
    "Extract triggers from either the visual or holo trigger channel. Automatic detection of Holographic recording. Check that the detection is perform on the right files. Perform triggers sanity checks for visual stimumi. You can plot them later on cell 4. Can take up to more than 1h to run all recordings depending on your experiment length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69655465",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------   Processing recording 1 out of 22   -------------\n",
      "\n",
      "The triggers are extracted from the sorting file:\t00_Checkerboard_30ND50%_20pix30checks_30Hz\n",
      "and the results will be saved at:\t\t\t/home/guiglaz/Documents/Pipeline_Git_Repo/Analysis/triggers/Pipeline_DEV_00_Checkerboard_30ND50%_20pix30checks_30Hz_triggers.pkl\n",
      "Trigers already extracted previously. Write again files files? Type Yes to do so :\n",
      "y\n",
      " /!\\ VISUAL Recording /!\\ \n",
      "Loading Data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e8fb4b9d0b4736bdaf0d6da851e62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66018000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 91\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m#Processing of data calling utils functions\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading Data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 91\u001b[0m data, t_tot    \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchannel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     93\u001b[0m indices        \u001b[38;5;241m=\u001b[39m detect_onsets(data,threshold)\n\u001b[1;32m     94\u001b[0m indices_errors \u001b[38;5;241m=\u001b[39m run_minimal_sanity_check(indices, stim_type \u001b[38;5;241m=\u001b[39m trigger_type)\n",
      "File \u001b[0;32m~/Documents/Pipeline_Git_Repo/Standard_analysis_pipeline/utils.py:101\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(input_path, dtype, nb_channels, channel_id, probe_size, voltage_resolution, disable)\u001b[0m\n\u001b[1;32m     99\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((nb_samples,), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(nb_samples),disable \u001b[38;5;241m=\u001b[39m disable):\n\u001b[0;32m--> 101\u001b[0m     data[k] \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnb_channels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchannel_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    102\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m    103\u001b[0m data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint16\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmin\n",
      "File \u001b[0;32m~/anaconda3/envs/spk/lib/python3.9/site-packages/numpy/core/memmap.py:334\u001b[0m, in \u001b[0;36mmemmap.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 334\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(res) \u001b[38;5;129;01mis\u001b[39;00m memmap \u001b[38;5;129;01mand\u001b[39;00m res\u001b[38;5;241m.\u001b[39m_mmap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mndarray)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Inputs\n",
    "\"\"\"\n",
    "\n",
    "#you can decide here to extract the triggers only for some recordings. List their indexes here (starting from 0).\n",
    "select_rec = []    # do only measurement N, put [] or the complet list to call all of them\n",
    "\n",
    "#You can manually enter here the recording numbers for which you want to manually select the recording type. \n",
    "rec_type_manual_selection = []\n",
    "\n",
    "#Erase already extracted triggers. If False, you'll have to manually confirm that you want to erase triggers \n",
    "extract_again = False\n",
    "\n",
    "\"\"\"\n",
    "    Variable\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you wan\n",
    "    t to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "#name of your experiment for saving the triggers\n",
    "exp = params.exp                     \n",
    "\n",
    "#the optimal threshhold for detecting stimuli onsets varies with the rig\n",
    "threshold = params.threshold\n",
    "\n",
    "# number of triggers samples acquired per second\n",
    "fs         = params.fs\n",
    "\n",
    "#The folder in which you want your triggers to be saved \n",
    "triggers_directory = params.triggers_directory\n",
    "\n",
    "#Channel recording triggers in case of holographic stimuli\n",
    "holo_channel_id   = params.holo_channel_id\n",
    "\n",
    "#Channel recording triggers in case of visual stimuli\n",
    "visual_channel_id = params.visual_channel_id \n",
    "\n",
    "#Datatype of the recording. If raws from the mcd files, put \"uint16\". If filtered raws, put \"int16\"\n",
    "dtype = params.dtype\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "\n",
    "for rec in range(len(recording_names)):\n",
    "\n",
    "    if select_rec:\n",
    "        if rec not in select_rec: continue\n",
    "    \n",
    "    print('\\n-------------   Processing recording {} out of {}   -------------\\n'.format(rec+1,len(link_names)))\n",
    "\n",
    "\n",
    "    # Creating all files path\n",
    "    input_file    = os.path.join(recording_directory,recording_names[rec]+r\".raw\")\n",
    "    trigger_file  = os.path.join(triggers_directory,'{}_{}_triggers.pkl'.format(exp,recording_names[rec]))\n",
    "    data_file     = os.path.join(triggers_directory,'{}_{}_triggers_data.pkl'.format(exp,recording_names[rec]))\n",
    "    \n",
    "    print('The triggers are extracted from the sorting file:\\t{}\\nand the results will be saved at:\\t\\t\\t{}'.format(recording_names[rec],trigger_file))\n",
    "\n",
    "    if os.path.exists(data_file) and not extract_again:\n",
    "        if (str(input('Trigers already extracted previously. Write again files files? Type Yes to do so :\\n')) not in [\"Y\", \"y\", \"yes\", \"Yes\"]) : continue\n",
    "    \n",
    "    if rec in rec_type_manual_selection:\n",
    "        if(str(input(\"Is this an holographic recording ? If yes, type Y :\")) in [\"Y\", \"y\", \"yes\", \"Yes\"]):\n",
    "            is_holo = True\n",
    "        else :\n",
    "            is_holo = False\n",
    "    else :\n",
    "            is_holo = is_holographic_rec(input_file, dtype=dtype, probe_size = time*fs)\n",
    "    \n",
    "    if is_holo: \n",
    "        #in this case the stimulus was holograpic\n",
    "        print(r\" /!\\ HOLOGRAPHIC Recording /!\\ \")\n",
    "        channel_id   = holo_channel_id\n",
    "        trigger_type = 'holo'\n",
    "        onsets_file  = os.path.join(triggers_directory,'{}_{}_laser_onsets.pkl'.format(exp,recording_names[rec]))\n",
    "        offsets_file  = os.path.join(triggers_directory,'{}_{}_laser_offsets.pkl'.format(exp,recording_names[rec]))\n",
    "\n",
    "    else: \n",
    "        #in this other case the stimulus was visual\n",
    "        print(r\" /!\\ VISUAL Recording /!\\ \")\n",
    "        channel_id   = visual_channel_id        \n",
    "        trigger_type = 'visual'\n",
    "        \n",
    "    #Processing of data calling utils functions\n",
    "    print(\"Loading Data...\")\n",
    "    data, t_tot    = load_data(input_file, channel_id = channel_id, dtype=dtype) \n",
    "                                      \n",
    "    indices        = detect_onsets(data,threshold)\n",
    "    indices_errors = run_minimal_sanity_check(indices, stim_type = trigger_type)\n",
    "    \n",
    "    #Saving data using utils function save_obj\n",
    "    save_obj({'indices':indices,'duration':t_tot,'trigger_type':trigger_type,'indice_errors':indices_errors}, trigger_file )\n",
    "    save_obj(data,data_file)\n",
    "\n",
    "    if trigger_type == 'holo':\n",
    "        offsets = detect_offsets(data)\n",
    "        \n",
    "        save_obj(indices, onsets_file)\n",
    "        save_obj(offsets, offsets_file)\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "    Output\n",
    "    \n",
    "    Saved in triggers_directory :\n",
    "\n",
    "{experience_name}_{link_file_name}_triggers.pkl (dict) : \n",
    "    keys 'indices'  --> detected triggers indices, \n",
    "         'duration' --> the stimuli duration, \n",
    "         'trigger_type'  --> the detection visual or holo stimuli, \n",
    "         'indice_errors' --> triggers violating sanity check \n",
    "         \n",
    "{experience_name}_{link_file_name}_triggers_data.pkl (numpy array) : raw signal recorded on the trigger channel\n",
    "\n",
    "\"\"\"\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd510d7",
   "metadata": {},
   "source": [
    "### CELL 4 : Plots triggers for sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad66dc09",
   "metadata": {},
   "source": [
    "#### <center>REQUIRES CELL 1 RUN & CELL 3 RUN AT LEAST ONCE FOR THIS EXPERIMENT </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e95f19b",
   "metadata": {},
   "source": [
    "Plots the raw trigger signal with the detected triggers and the errors detected. Independently, plots also the detected triggers, should be a perfect diagonal. Third, plots the number of time points gap to the most common trigger duration (ie theoretical_time_per_frame +- ploted value)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65824ebf",
   "metadata": {},
   "source": [
    "#### <center>/!\\/!\\/!\\ Caution on memory leaks /!\\/!\\/!\\ </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a39ec5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 00_AccCechkerboard_30Hz_20px_30sq_50%-30ND\n",
      "1 : 01_Checkerboard_30Hz_16px_40sq_50%-30ND\n",
      "2 : 02_Chirp_50Hz_50%-30ND\n",
      "3 : 03_DG_50Hz_50%-30ND\n",
      "4 : 04_Flicker_BeforeLAP4+ACET_30ND50%_1Hz\n",
      "5 : 05_Flicker_AfterLAP4+ACET+30min_30ND50%_1Hz\n",
      "6 : 06_HoloStim1_LAP4+ACET_Z(-30)\n",
      "7 : 06_HoloStim1_LAP4+ACET_Z(-30)0001\n",
      "8 : 07_Flicker_1Hz_50%-15ND_After-LAP4-ACET-Before-SR95531\n",
      "9 : 08_Flicker_1Hz_50%-15ND_After-LAP4-ACET-SR95531-t30\n",
      "10 : 09_HoloStim2_LAP4+ACET+SR95531_Z(-30)\n",
      "\n",
      "Select recording : 10\n",
      "\n",
      "\t\t\t------ End Of Cell ------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Variable\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "#Experiment name\n",
    "exp = params.exp\n",
    "\n",
    "# Optimal threshhold for detecting stimuli onsets varies with the rig\n",
    "threshold  = params.threshold\n",
    "\n",
    "# Directory where plots will be saved\n",
    "output_directory = params.output_directory\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Inputs\n",
    "\"\"\"\n",
    "\n",
    "#Set True if you want the plots to be saved\n",
    "save = False\n",
    "\n",
    "#Define your x-axis ploting window in a tuple (x-min,x-max). Set False to plot the complete data\n",
    "ploting_range = False\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Ploting\n",
    "\"\"\"\n",
    "\n",
    "print(*['{} : {}'.format(i,recording_name) for i, recording_name in enumerate(recording_names)], sep=\"\\n\")\n",
    "recordings = [int(rec_id) for rec_id in input(\"\\nSelect recording : \").split()]\n",
    "\n",
    "\n",
    "plt.close('all')\n",
    "gc.collect()\n",
    "plot_idx = 0\n",
    "\n",
    "for rec in recordings:\n",
    "    plot_idx+=1\n",
    "    # Loading data from pickle files created in cell 3\n",
    "    data    = np.array(load_obj(os.path.normpath(os.path.join(params.triggers_directory,'{}_{}_triggers_data.pkl'.format(exp,recording_names[rec])))))\n",
    "    extracted = load_obj(os.path.normpath(os.path.join(params.triggers_directory,'{}_{}_triggers.pkl'.format(exp,recording_names[rec]))))\n",
    "    err = extracted['indice_errors']\n",
    "    indices = extracted['indices']\n",
    "    rec_type = extracted[\"trigger_type\"]\n",
    "    \n",
    "    # If ploting range is a tuple, reduce the plot to indices between both values of the tuple\n",
    "    if ploting_range :\n",
    "        indices = indices[np.logical_and(indices > ploting_range[0], indices < ploting_range[1])]\n",
    "        data    = data[np.logical_and(np.array(range(len(data))) > ploting_range[0], np.array(range(len(data))) < ploting_range[1])]\n",
    "        err     = err[np.logical_and(err > ploting_range[0], err < ploting_range[1])]\n",
    "    \n",
    "    plt.figure(\"Trigger sanity check {}\".format(plot_idx))\n",
    "    \n",
    "    # Top plot with raw trigger signal, threshold of detection, detected triggers and wrong triggers\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.title('{}\\n{} channel'.format(recording_names[rec],rec_type))\n",
    "    \n",
    "    plt.plot(np.linspace(0,len(data)/fs,len(data) ),data)\n",
    "    plt.plot(indices/fs,data[indices],'.',markersize=2,zorder=10)\n",
    "\n",
    "    plt.axhline(threshold, color='green')\n",
    "    plt.scatter(err/fs,data[err], color='red', marker='x',zorder = 15)\n",
    "    \n",
    "    # Bottom left plot of triggers indices. Shoule be a perfect diagonal\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.plot(indices)\n",
    "    plt.title('Detected indices')\n",
    "    \n",
    "    # Bottom right plot of relative error gap between detect time of frame and mean frame time\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.plot(np.diff(np.diff(indices)))\n",
    "    try :\n",
    "        plt.title('Duration {} +- error'.format(np.round(np.mean(np.diff(indices)))))\n",
    "    except :\n",
    "        plt.title('Duration {} +- error'.format(\"NOT COMPUTED\"))\n",
    "                  \n",
    "    plt.tight_layout()\n",
    "    plt.show(block = False)\n",
    "    \n",
    "    # Saving plot if needed\n",
    "    if save:\n",
    "        fig_name = os.path.join(output_directory,r'{}_{}.png'.format(recording_names[rec],link_names[rec]))\n",
    "        plt.savefig(fig_name)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Output\n",
    "    \n",
    "    if save == True\n",
    "    \n",
    "    {recording_file_name}_{link_file_name}.png : Plots for a given recording file\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97874f0c",
   "metadata": {},
   "source": [
    "### Cell 5 : Dead times file creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b129352c",
   "metadata": {},
   "source": [
    "#### <center>REQUIRES CELL 1 RUN & CELL 3 RUN AT LEAST ONCE FOR THIS EXPERIMENT </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943a1311",
   "metadata": {},
   "source": [
    "Run minimal sanity check on visual triggers and create the dead times in sec for holographic stimuli. If you only have visual triggers, running this cell isn't mandatory, it only provides a repeated sanity check for visual stims..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19117ee9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording 0 :\t1-Checkerboard_40hz_12px_60sq.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Recording 1 :\t2-Chirp_50hz.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Recording 2 :\t3-DG_50hz.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Recording 3 :\t3-DG_50hz_bis.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Recording 4 :\t4-Moving_disks_r7_40hz.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Recording 5 :\t5-Moving_disks_r10_40hz.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Recording 6 :\t6-Moving_disks_r14_40hz.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Recording 7 :\t7-Chirp_End_50hz.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Recording 8 :\t8-Checkerboard_End_40hz_12px_60sq.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Writting dead times file for 0 holographic recordings...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Variable\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "#name of your experiment for saving the triggers\n",
    "exp = params.exp\n",
    "\n",
    "#The folder in which you saved your triggers\n",
    "triggers_directory = params.triggers_directory\n",
    "\n",
    "#The folder containing raw recording files\n",
    "recording_directory = params.recording_directory\n",
    "\n",
    "# Directory where dead_times file will be saved\n",
    "output_directory = params.output_directory\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "plt.close(\"all\")\n",
    "gc.collect()\n",
    "\n",
    "rec_onsets    = recording_onsets(recording_names, path = recording_directory)  \n",
    "\n",
    "holo_onsets   = []\n",
    "holo_triggers = []\n",
    "for rec in range(len(recording_names)):\n",
    "    \n",
    "    #Loading data\n",
    "    trig_data = load_obj(os.path.normpath(os.path.join(params.triggers_directory,'{}_{}_triggers.pkl'.format(exp,recording_names[rec]))))\n",
    "    \n",
    "    \n",
    "    if trig_data['trigger_type']=='holo':\n",
    "        #If recording was detected as holographic\n",
    "        print('Recording {} detected as holographic :\\t{}'.format(rec, recording_names[rec]))\n",
    "        holo_onsets.append(rec_onsets[recording_names[rec]])\n",
    "        holo_triggers.append(trig_data['indices'])\n",
    "        print('Number of triggers to be added to dead times file : {}'.format(len(trig_data['indices'])))\n",
    "        \n",
    "    else:\n",
    "        #Otherwise it is considered as visual\n",
    "        print('Recording {} :\\t{}'.format(rec, recording_names[rec]))\n",
    "        err = run_minimal_sanity_check(trig_data['indices'])    \n",
    "    print('\\n')\n",
    "\n",
    "print('Writting dead times file for {} holographic recordings...'.format(len(holo_triggers)))\n",
    "#Writting .dead file using utils function\n",
    "write_dead_times_file(holo_triggers,holo_onsets, output_directory)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Ploting\n",
    "\"\"\"\n",
    "\n",
    "#Potting once more the recordings onsets similarly to cell 2\n",
    "ticks=[]\n",
    "plt.ioff()\n",
    "plt.close('all')\n",
    "plt.figure() \n",
    "for rec in range(len(recording_names)):\n",
    "    plt.axhline(rec_onsets[recording_names[rec]]/params.fs/60)\n",
    "    ticks.append(rec_onsets[recording_names[rec]]/params.fs/60)\n",
    "    \n",
    "plt.yticks(ticks)\n",
    "plt.title('Recording starting time')\n",
    "plt.ylabel('Minutes')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Output\n",
    "    \n",
    "    {recording_file_name}_dead_times.dead : dead time file given times to exclude in spyking circus\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c0845b",
   "metadata": {},
   "source": [
    "## Run Spyking Circus 1 sorting algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b658fd",
   "metadata": {},
   "source": [
    "Run spyking circus:<br>\n",
    "<br> >> conda activate circus1'\n",
    "<br> >> spyking-circus recording_00.raw -p\n",
    "<i>(if everything looks good continue)</i>\n",
    "<br> >> spyking-circus recording_00.raw -c 10\n",
    "<i>(run the sorting on half of your cores)</i>\n",
    "<br> >> spyking-circus rcording_00.raw -c 10 -m converting <i>(export to phy's format)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e0470",
   "metadata": {},
   "source": [
    "# <center>/!\\/!\\/!\\ Run this after the sorting /!\\/!\\/!\\ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59361bc0",
   "metadata": {},
   "source": [
    "### Cell 6 : Creating all clusters rasters plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa73fb",
   "metadata": {},
   "source": [
    "#### <center>REQUIRES CELL 1 RUN</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde0d8e5",
   "metadata": {},
   "source": [
    "Run after automatic sorting to help with manual sorting. Saves all automatic clusters' rasters on the repeated checherboard in the phy directory. You can run this several times during sorting to make new clusters rasters. Can take few sec per cluster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a54aae9b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spike extraction: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d888cba92b4f45c4ac74c96077337f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25264531 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster to Spikes matching: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42a56356fd5497db7fa2784645c01b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 00_Checkerboard_30ND50%_20pix30checks_30Hz\n",
      "1 : 01_Checkerboard_30ND50%_16pix40checks_30Hz\n",
      "2 : 02_DG_30ND50%_2sT_50Hz\n",
      "3 : 03_Chirp_20reps_30ND50%_50Hz\n",
      "4 : 04_Flicker_BeforeDrugs_30ND50%_1Hz\n",
      "5 : 05_VDH_Synchro+MultiSpots(bright)_N8_Z(-35)_30ND50%_40Hz\n",
      "6 : 06_VDH_Synchro_N10_Z(-35)_30ND50%_40Hz\n",
      "7 : 07_Flicker_LAP4+ACET_t+10_30ND50%_1Hz\n",
      "8 : 08_HoloStim1_LAP4+ACET_N8_Z(-35)\n",
      "9 : 09_HoloStim1_LAP4+ACET_N15_Z(-30)\n",
      "10 : 10_OptoStim1_LAP4+ACET_15ND50%_1Hz\n",
      "11 : 11_OptoStim1_LAP4+ACET_5ND50%_1Hz\n",
      "12 : 12_HoloStim2_GRF_t30_N15_Z(-30)\n",
      "13 : 13_OptoStim2_GRF_t35_15ND50%_1Hz\n",
      "14 : 14_OptoStim2_GRF_t40_5ND50%_1Hz\n",
      "15 : 15_HoloStim3_SR95531_t30_N15_Z(-30)\n",
      "16 : 16_OptoStim3_SR95531_t35_15ND50%_1Hz\n",
      "17 : 17_OptoStim3_SR95531_t40_5ND50%_1Hz\n",
      "18 : 18_HoloStim3_18BG_t5_N15_Z(-30)\n",
      "19 : 19_OptoStim3_18BG_t10_15ND50%_1Hz\n",
      "20 : 20_OptoStim3_18BG_t15_5ND50%_1Hz\n",
      "21 : 21_HoloStim3_18BG_t20_N15_Z(-30)\n",
      "\n",
      "Select the checkerboard recording  for the raster plots: 1\n",
      "Building Raster plots : \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a26693f77740a2928ce3eb10babef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving rasters plots of all clusters :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699960d06a994f9c8b943aa5fbf43983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t\t------ End Of Cell ------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Variable\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "#length of each sequence composed of half repeated sequence and half random sequence\n",
    "\n",
    "nb_frames_by_sequence = params.nb_frames_by_sequence\n",
    "\n",
    "# Name of your experiment\n",
    "exp = params.exp\n",
    "\n",
    "#Path to the folder with the phy output\n",
    "phy_directory = params.phy_directory\n",
    "\n",
    "#Path to raw recording files\n",
    "recording_directory = params.recording_directory\n",
    "\n",
    "#Frequency of sampling of the mea\n",
    "fs = params.fs\n",
    "\n",
    "\"\"\"\n",
    "    Input\n",
    "\"\"\"\n",
    "#Number of the checkerboard recording of choice (start from zero)\n",
    "check_recording_number = 0\n",
    "\n",
    "#Checkerboard frequency in Hz\n",
    "stimulus_frequency = 30\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "###################################\n",
    "#### Loading phy clusters info ####\n",
    "###################################\n",
    "plt.close(\"all\")\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "rec_onsets = recording_onsets(recording_names, path = recording_directory)  \n",
    "\n",
    "# Get cells index and number\n",
    "cluster_number , good_clusters = extract_cluster_groups(phy_directory)\n",
    "\n",
    "# Extract the spike times from the spike sorting files. This can take a few minutes.\n",
    "print('Spike extraction: ')\n",
    "all_spike_times = extract_all_spike_times_from_phy(phy_directory)\n",
    "\n",
    "print('Cluster to Spikes matching: ')\n",
    "# create a dictionary with another dictionary for each cluster\n",
    "all_neurons_data = split_spikes_by_recording(all_spike_times, cluster_number, rec_onsets)\n",
    "\n",
    "\n",
    "#############################\n",
    "#### Making raster plots ####\n",
    "#############################\n",
    "\n",
    "print(*['{} : {}'.format(i,recording_name) for i, recording_name in enumerate(recording_names)], sep=\"\\n\")\n",
    "check_recording_number = int(input(\"\\nSelect the checkerboard recording  for the raster plots: \"))\n",
    "\n",
    "checkerboard_name = recording_names[check_recording_number]\n",
    "\n",
    "checkerboard_spikes = get_recording_spikes(checkerboard_name, all_neurons_data)\n",
    "\n",
    "trig_data = load_obj(os.path.normpath(os.path.join(params.triggers_directory,'{}_{}_triggers.pkl'.format(exp,checkerboard_name))))\n",
    "triggers = trig_data['indices']/fs\n",
    "raster_data = {}\n",
    "\n",
    "print('Building Raster plots : ')\n",
    "for (cell_nb, spike_times) in tqdm(checkerboard_spikes.items()):\n",
    "    # Align triggers and spike times\n",
    "    aligned_triggers, aligned_spike_times = align_triggers_spikes(triggers, spike_times)\n",
    "    \n",
    "    # Get rasters on repeated sequence\n",
    "    raster_data[cell_nb] = build_rasters(aligned_spike_times, aligned_triggers, stim_frequency = stimulus_frequency)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Saving\n",
    "\"\"\"\n",
    "\n",
    "#Save all clusters rasters plots    \n",
    "fig_directory = os.path.normpath(os.path.join(phy_directory,r'clusters_rasters_{}'.format(check_recording_number)))\n",
    "if not os.path.isdir(fig_directory): os.makedirs(fig_directory)\n",
    "\n",
    "    \n",
    "print(\"Saving rasters plots of all clusters :\")\n",
    "for cell_nb in tqdm(raster_data.keys()):\n",
    "    fig, axs = plt.subplots(nrows = 2,ncols = 1, sharex=True, gridspec_kw={'height_ratios': [3, 1]}, figsize=(10,10))\n",
    "\n",
    "    plt.suptitle(f'Cell {cell_nb}')\n",
    "\n",
    "    ax_rast = axs[0]\n",
    "    ax_rast.eventplot(raster_data[cell_nb][\"spike_trains\"])\n",
    "    ax_rast.set(title = \"Raster plot\", ylabel='N Repetitions')\n",
    "\n",
    "    ax_psth = axs[1]\n",
    "    width = (raster_data[cell_nb][\"repeated_sequences_times\"][0][0]/600)\n",
    "    ax_psth.bar(np.linspace(0,raster_data[cell_nb][\"repeated_sequences_times\"][0][0],int(nb_frames_by_sequence/2))+width/2, raster_data[cell_nb][\"psth\"], width=1.3*width)\n",
    "    ax_psth.set(xlabel='Time in sec', ylabel='Firing rate (spikes/s)')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig_file = os.path.normpath(os.path.join(fig_directory,f'Cluster_{cell_nb}.png'))\n",
    "    plt.savefig(fig_file, dpi=fig.dpi)\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "\"\"\"\n",
    "    Output\n",
    "    \n",
    "    Save :\n",
    "    \n",
    "    \"\"{phy_directory}/clusters_rasters/Cluster_{Cluster_number}.png\" for each found clusters in phy's files\n",
    "\"\"\"    \n",
    "\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40d3bb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m17:54:24.170 [W] model:625            Unreferenced clusters found in spike_clusters (generally not a problem)\u001b[0m\n",
      "\u001b[33m17:54:25.600 [W] model:667            Skipping spike waveforms that do not exist, they will be extracted on the fly from the raw data as needed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import params\n",
    "out = f\"phy template-gui {params.phy_directory}/params.py\"\n",
    "\n",
    "!env QTWEBENGINE_CHROMIUM_FLAGS=\"--single-process\" {out}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84f6b6",
   "metadata": {},
   "source": [
    "### Cell 7 : Extract data per neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76ed40b",
   "metadata": {},
   "source": [
    "#### <center>REQUIRES CELL 1 RUN</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a953b24",
   "metadata": {},
   "source": [
    "Extract all data from phy numpy variables. Create&save a dictionnary containg spikes times in sec for each neuron splited by recording. Depending on your experiment, this can take severeal minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ead816c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 276 good clusters (570 clusters in total)\n",
      "\n",
      "Spike extraction: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40d5ec65e5643dfb59be4fbc2c606dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25264531 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Spike division in recordings per neuron:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ebba536c36419e899542cefea52ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t\t------ End Of Cell ------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Variable\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "# Name of your experiment\n",
    "exp = params.exp\n",
    "\n",
    "#Path to the folder with the phy output\n",
    "phy_directory = params.phy_directory\n",
    "\n",
    "#Path to where data should be saved\n",
    "output_directory = params.output_directory\n",
    "\n",
    "#Path to raw recording files\n",
    "recording_directory = params.recording_directory\n",
    "\n",
    "#Frequency of sampling of the mea\n",
    "fs = params.fs\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "\n",
    "rec_onsets    = recording_onsets(recording_names, path = recording_directory)  \n",
    "\n",
    "# Get cells index and number\n",
    "cluster_number , good_clusters = extract_cluster_groups(phy_directory)\n",
    "print(\"There are {} good clusters ({} clusters in total)\\n\".format(len(good_clusters), len(cluster_number)))\n",
    "\n",
    "\n",
    "# Extract the spike times from the spike sorting files. This can take a few minutes.\n",
    "print('Spike extraction: ')\n",
    "all_spike_times = extract_all_spike_times_from_phy(phy_directory)\n",
    "\n",
    "print('\\n')\n",
    "print('Spike division in recordings per neuron:')\n",
    "# create a dictionary with another dictionary for each good cluster\n",
    "good_data = split_spikes_by_recording(all_spike_times, good_clusters, rec_onsets)\n",
    "\n",
    "\n",
    "# Save the spike data. This can take a few minutes.\n",
    "good_data_file_name = os.path.join(output_directory,r'{}_fullexp_neurons_data.pkl'.format(exp))\n",
    "save_obj(good_data,good_data_file_name)\n",
    "\n",
    "\"\"\"\n",
    "    Output\n",
    "    \n",
    "    data (dict) : key 'cluster_id' --> (dict) key 'recording_name' --> This neuron & this recording spikes times in sec\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
