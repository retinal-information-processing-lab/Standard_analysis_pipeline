{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad00f68f",
   "metadata": {},
   "source": [
    "# <center>Preprocessing Data Analysis</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d3bb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing spike interface, this may take a while...\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"Importing spike interface, this may take a while...\")\n",
    "import spikeinterface.full as si\n",
    "print(\"Done...\")\n",
    "import scipy\n",
    "\n",
    "import probeinterface as pi\n",
    "from probeinterface.plotting import plot_probe_group, plot_probe\n",
    "\n",
    "# Load probe\n",
    "probe = pi.read_prb('mcs_256_30_8iR_ITO.prb')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('qt5agg')\n",
    "\n",
    "from utils import *         # Local file containing all the functions that we need\n",
    "import params               # Parameters file. You should tune it for your own experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de83b9",
   "metadata": {},
   "source": [
    "# Run this before the sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79df1167",
   "metadata": {},
   "source": [
    "### Cell 1: Create Symbolic links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a206117",
   "metadata": {},
   "source": [
    "As spyking circus requires a specific file format, we create here symbolic links to the raw recording file with the right Spyking circus format. This cell contains important variable for the rest of the notebook. You should check stim duration as sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4158816f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of recordings: 22\n",
      "\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_00.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_01.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_02.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_03.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_04.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_05.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_06.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_07.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_08.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_09.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_10.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_11.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_12.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_13.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_14.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_15.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_16.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_17.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_18.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_19.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_20.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\u001b[33m/!\\ File /home/guiglaz/Documents/Pipeline Git Repo/Sorting/recording_21.raw already exists /!\\ \u001b[0m\n",
      "\u001b[33m\t\tMay not be a problem if you already run this code for THIS experiment\n",
      "\u001b[0m\n",
      "\n",
      "Check that the name and the recording number match in the links file\n",
      "\n",
      "created link recording_00.raw\t55 minutes\t already existed\t00_Checkerboard_30ND50%_20pix30checks_30Hz_Filtered\n",
      "created link recording_01.raw\t24 minutes\t already existed\t01_Checkerboard_30ND50%_16pix40checks_30Hz_Filtered\n",
      "created link recording_02.raw\t6 minutes\t already existed\t02_DG_30ND50%_2sT_50Hz_Filtered\n",
      "created link recording_03.raw\t11 minutes\t already existed\t03_Chirp_20reps_30ND50%_50Hz_Filtered\n",
      "created link recording_04.raw\t5 minutes\t already existed\t04_Flicker_BeforeDrugs_30ND50%_1Hz_Filtered\n",
      "created link recording_05.raw\t115 minutes\t already existed\t05_VDH_Synchro+MultiSpots(bright)_N8_Z(-35)_30ND50%_40Hz_Filtered_Cleaned_Zeros\n",
      "created link recording_06.raw\t16 minutes\t already existed\t06_VDH_Synchro_N10_Z(-35)_30ND50%_40Hz_Filtered_Cleaned_Zeros\n",
      "created link recording_07.raw\t4 minutes\t already existed\t07_Flicker_LAP4+ACET_t+10_30ND50%_1Hz_Filtered\n",
      "created link recording_08.raw\t3 minutes\t already existed\t08_HoloStim1_LAP4+ACET_N8_Z(-35)_Filtered_Cleaned_Zeros\n",
      "created link recording_09.raw\t5 minutes\t already existed\t09_HoloStim1_LAP4+ACET_N15_Z(-30)_Filtered_Cleaned_Zeros\n",
      "created link recording_10.raw\t5 minutes\t already existed\t10_OptoStim1_LAP4+ACET_15ND50%_1Hz_Filtered\n",
      "created link recording_11.raw\t5 minutes\t already existed\t11_OptoStim1_LAP4+ACET_5ND50%_1Hz_Filtered\n",
      "created link recording_12.raw\t5 minutes\t already existed\t12_HoloStim2_GRF_t30_N15_Z(-30)_Filtered_Cleaned_Zeros\n",
      "created link recording_13.raw\t5 minutes\t already existed\t13_OptoStim2_GRF_t35_15ND50%_1Hz_Filtered\n",
      "created link recording_14.raw\t3 minutes\t already existed\t14_OptoStim2_GRF_t40_5ND50%_1Hz_Filtered\n",
      "created link recording_15.raw\t5 minutes\t already existed\t15_HoloStim3_SR95531_t30_N15_Z(-30)_Filtered_Cleaned_Zeros\n",
      "created link recording_16.raw\t5 minutes\t already existed\t16_OptoStim3_SR95531_t35_15ND50%_1Hz_Filtered\n",
      "created link recording_17.raw\t4 minutes\t already existed\t17_OptoStim3_SR95531_t40_5ND50%_1Hz_Filtered\n",
      "created link recording_18.raw\t5 minutes\t already existed\t18_HoloStim3_18BG_t5_N15_Z(-30)_Filtered_Cleaned_Zeros\n",
      "created link recording_19.raw\t4 minutes\t already existed\t19_OptoStim3_18BG_t10_15ND50%_1Hz_Filtered\n",
      "created link recording_20.raw\t4 minutes\t already existed\t20_OptoStim3_18BG_t15_5ND50%_1Hz_Filtered\n",
      "created link recording_21.raw\t5 minutes\t already existed\t21_HoloStim3_18BG_t20_N15_Z(-30)_Filtered_Cleaned_Zeros\n",
      "\n",
      "\t\t\t------ End Of Cell ------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Variables\n",
    "    \n",
    "    DO NOT CHANGE VALUES HERE UNLESS DEBUG/SPECIFIC USE\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "#Link to the actual raw files from the recording listed in the input_file\n",
    "recording_directory     = params.recording_directory\n",
    "\n",
    "#Loading raw recording files names\n",
    "recording_names = params.recording_names\n",
    "\n",
    "symbolic_link_directory = params.symbolic_link_directory\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "\n",
    "#recording_names = [rec.split(r'.raw')[0]+r'.raw' for rec in recording_names]\n",
    "print('Number of recordings: {}\\n'.format(len(recording_names)))\n",
    "#Creates links\n",
    "link_names, previously_existing = create_symlinks([rec+r'.raw' for rec in recording_names], symbolic_link_directory, recording_directory)\n",
    "\n",
    "#getting onset for next prints\n",
    "onsets = {}\n",
    "onsets = recording_onsets(link_names, path = symbolic_link_directory)\n",
    "\n",
    "#Printing results\n",
    "print('\\nCheck that the name and the recording number match in the links file\\n') \n",
    "link_names_it = link_names[:]\n",
    "link_names_it.append('end')\n",
    "for i in range(len(link_names_it)-1):\n",
    "    print(\"created link {}\\t{} minutes\\t{}\\t{}\".format(\n",
    "        link_names[i], \n",
    "        int((onsets[link_names_it[i+1]] - onsets[link_names_it[i]])/params.fs/60), \n",
    "        previously_existing[i],\n",
    "        recording_names[i]))\n",
    "\n",
    "\n",
    "\"\"\"Output :\n",
    "\n",
    "Saved :\n",
    "Symbolic links have been created\n",
    "\n",
    "Var :\n",
    "recordings_names : Ordered list of stimuli names played during experiment\n",
    "link_names       : Ordered list of links names to recording files to follow spyking_circus requirements   \n",
    "\"\"\"   \n",
    "\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e0ebf",
   "metadata": {},
   "source": [
    "### Cell 2 : Sanity checks of symlinks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756ad360",
   "metadata": {},
   "source": [
    "#### <center>REQUIRES CELL 1 RUN</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f4b44",
   "metadata": {},
   "source": [
    "Sanity checks of symlinks comparing onsets recorded from raw files and onsets recorded from symlinks. If both plots are identical, it is likely that links point to the right recording files. Otherwise, links are pointing to the wrong files. You may want to check your params.py file for a wrong directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d64f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Make sure both plots are identical\n",
      "\n",
      "\t\t\t------ End Of Cell ------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Variables\n",
    "    \n",
    "    DO NOT CHANGE VALUES HERE UNLESS DEBUG/SPECIFIC USE\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "#Link to the folder where spiking circus will look for the symbolic links \"recording_0i.raw\"\n",
    "symbolic_link_directory = params.symbolic_link_directory\n",
    "\n",
    "#Link to the actual raw files from the recording listed in the input_file\n",
    "recording_directory     = params.recording_directory\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "\n",
    "rec_onsets  = recording_onsets(recording_names, path = recording_directory)\n",
    "\n",
    "link_onsets = recording_onsets(link_names, path = symbolic_link_directory)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Ploting\n",
    "\"\"\"\n",
    "print(\"\\nMake sure both plots are identical\")\n",
    "plt.ioff()\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "\n",
    "# LEFT PLOT\n",
    "ticks=[]\n",
    "plt.subplot(1,2,1)\n",
    "for rec in recording_names:\n",
    "    plt.axhline(rec_onsets[rec]/params.fs/60)\n",
    "    ticks.append(rec_onsets[rec]/params.fs/60)\n",
    "plt.axhline(rec_onsets['end']/params.fs/60)\n",
    "ticks.append(rec_onsets['end']/params.fs/60)\n",
    "\n",
    "plt.yticks(ticks)\n",
    "plt.title('Recordings onsets')\n",
    "plt.ylabel('Minutes')\n",
    "\n",
    "# RIGHT PLOT\n",
    "ticks=[]\n",
    "plt.subplot(1,2,2)\n",
    "for rec in link_names:\n",
    "    plt.axhline(link_onsets[rec]/params.fs/60)\n",
    "    ticks.append(link_onsets[rec]/params.fs/60)\n",
    "plt.axhline(link_onsets['end']/params.fs/60)\n",
    "ticks.append(link_onsets['end']/params.fs/60)\n",
    "plt.yticks(ticks)\n",
    "plt.title('Links onsets')\n",
    "plt.ylabel('Minutes')\n",
    "\n",
    "plt.show(block = False)\n",
    "\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ecdb2a",
   "metadata": {},
   "source": [
    "### Cell 3 : Extract the triggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b9255e",
   "metadata": {},
   "source": [
    "#### <center>REQUIRES CELL 1 RUN</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb53ca0",
   "metadata": {},
   "source": [
    "Extract triggers from either the visual or holo trigger channel. Automatic detection of Holographic recording. Check that the detection is perform on the right files. Perform triggers sanity checks for visual stimumi. You can plot them later on cell 4. Can take up to more than 1h to run all recordings depending on your experiment length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69655465",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guiglaz/Documents/Pipeline Git Repo/Standard_analysis_pipeline/utils.py:319: DeprecationWarning: invalid escape sequence \\ \n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------   Processing recording 3 out of 22   -------------\n",
      "\n",
      "The triggers are extracted from the sorting file:\t03_Chirp_20reps_30ND50%_50Hz_Filtered\n",
      "and the results will be saved at:\t\t\t/home/guiglaz/Documents/Pipeline Git Repo/Analysis/triggers/Pipeline_DEV_03_Chirp_20reps_30ND50%_50Hz_Filtered_triggers.pkl\n",
      "Detected as holographic : True\n",
      "Is this an holographic recording ? If yes, type Y :\n",
      " /!\\ VISUAL Recording /!\\ \n",
      "Loading Data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6c925c71c84b058ffbaedd888cc8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13414000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal sanity checks :\t/!\\ Triggers are not evenly spaced /!\\ \n",
      "Number of errors : 410959\n",
      "Maximum error : 84 sampling points compared to 4 sampling points per trigger\n",
      "\n",
      "-------------   Processing recording 4 out of 22   -------------\n",
      "\n",
      "The triggers are extracted from the sorting file:\t07_Flicker_LAP4+ACET_t+10_30ND50%_1Hz_Filtered\n",
      "and the results will be saved at:\t\t\t/home/guiglaz/Documents/Pipeline Git Repo/Analysis/triggers/Pipeline_DEV_07_Flicker_LAP4+ACET_t+10_30ND50%_1Hz_Filtered_triggers.pkl\n",
      "Detected as holographic : False\n",
      "Is this an holographic recording ? If yes, type Y :\n",
      " /!\\ VISUAL Recording /!\\ \n",
      "Loading Data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32dace9521d84d808764c1fd56c650a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5496000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal sanity checks :\t/!\\ Triggers are not evenly spaced /!\\ \n",
      "Number of errors : 244151\n",
      "Maximum error : 75 sampling points compared to 4 sampling points per trigger\n",
      "\n",
      "\t\t\t------ End Of Cell ------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Variable\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "#name of your experiment for saving the triggers\n",
    "exp = params.exp\n",
    "\n",
    "# select MEA (3=2p room) (4=MEA1 Polycrhome)\n",
    "MEA = params.MEA                       \n",
    "\n",
    "#the optimal threshhold for detecting stimuli onsets varies with the rig\n",
    "threshold  = params.threshold           \n",
    "\n",
    "Nchannels  = params.nb_channels                #256 for standard MEA, 17 for MEA1 Polychrome\n",
    "\n",
    "# number of triggers samples acquired per second\n",
    "fs         = params.fs\n",
    "\n",
    "# number of time points used to check if a recording is holographic or not\n",
    "probe_size = params.probe_size\n",
    "\n",
    "#The folder in which you want your triggers to be saved \n",
    "triggers_directory = params.triggers_directory\n",
    "\n",
    "#Channel recording triggers in case of holographic stimuli\n",
    "holo_channel_id   = params.holo_channel_id\n",
    "\n",
    "#Channel recording triggers in case of visual stimuli\n",
    "visual_channel_id = params.visual_channel_id \n",
    "\n",
    "\"\"\"\n",
    "    Inputs\n",
    "\"\"\"\n",
    "\n",
    "#you can decide here to extract the triggers only for some recordings. List their indexes here (starting from 0).\n",
    "select_rec = [2,3]    # do only measurement N, put [] or the complet list to call all of them\n",
    "\n",
    "#You can manually enter here the recording numbers for which you want to manually select the recording type. \n",
    "rec_type_manual_selection = [2,3]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "\n",
    "for rec in range(len(recording_names)):\n",
    "\n",
    "    if select_rec:\n",
    "        if rec not in select_rec: continue\n",
    "    \n",
    "    print('\\n-------------   Processing recording {} out of {}   -------------\\n'.format(rec+1,len(link_names)))\n",
    "\n",
    "\n",
    "    # Creating all files path\n",
    "    input_file    = os.path.join(symbolic_link_directory,link_names[rec])\n",
    "    trigger_file  = os.path.join(triggers_directory,'{}_{}_triggers.pkl'.format(exp,recording_names[rec]))\n",
    "    data_file     = os.path.join(triggers_directory,'{}_{}_triggers_data.pkl'.format(exp,recording_names[rec]))\n",
    "    \n",
    "    print('The triggers are extracted from the sorting file:\\t{}\\nand the results will be saved at:\\t\\t\\t{}'.format(recording_names[rec],trigger_file))\n",
    "\n",
    "    if os.path.exists(data_file):\n",
    "        if (str(input('Trigers already extracted previously. Write again files files? Type Y to do so :\\n')) != 'Y') : continue\n",
    "    \n",
    "    if rec in rec_type_manual_selection:\n",
    "        print(f\"Detected as holographic : {is_holo}\")\n",
    "        if(str(input(\"Is this an holographic recording ? If yes, type Y :\")) == \"Y\"):\n",
    "            is_holo = True\n",
    "        else :\n",
    "            is_holo = False\n",
    "    else :\n",
    "            is_holo = is_holographic_rec(input_file)\n",
    "    \n",
    "    \n",
    "    if is_holo: \n",
    "        #in this case the stimulus was holograpic\n",
    "        print(r\" /!\\ HOLOGRAPHIC Recording /!\\ \")\n",
    "        channel_id   = holo_channel_id\n",
    "        trigger_type = 'holo'\n",
    "    else: \n",
    "        #in this other case the stimulus was visual\n",
    "        print(r\" /!\\ VISUAL Recording /!\\ \")\n",
    "        channel_id   = visual_channel_id        \n",
    "        trigger_type = 'visual'\n",
    "        onsets_file  = os.path.join(triggers_directory,'{}_{}_laser_onsets.pkl'.format(exp,recording_names[rec]))\n",
    "        offsets_file  = os.path.join(triggers_directory,'{}_{}_laser_offsets.pkl'.format(exp,recording_names[rec]))\n",
    "\n",
    "    #Processing of data calling utils functions\n",
    "    print(\"Loading Data...\")\n",
    "    data, t_tot    = load_data(input_file, channel_id = channel_id )  #MANUALLY CHANGE HERE IF THE CHANNEL IS \n",
    "                                                                     #AUTHOMATICALLY MISDETECTED. IF SO IT SHOULD \n",
    "                                                                    #BE BECAUSE OF ALIASING OR BAD TRIGGER QUALITY\n",
    "    indices        = detect_onsets(data,threshold)\n",
    "    indices_errors = run_minimal_sanity_check(indices, stim_type = trigger_type)\n",
    "    \n",
    "    #Saving data using utils function save_obj\n",
    "    save_obj({'indices':indices,'duration':t_tot,'trigger_type':trigger_type,'indice_errors':indices_errors}, trigger_file )\n",
    "    save_obj(data,data_file)\n",
    "\n",
    "    if trigger_type == 'holo':\n",
    "        save_obj(onsets_file, indices)\n",
    "    \n",
    "        offsets = detect_offsets(data)\n",
    "        np.save(offsets_file, offsets)\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "    Output\n",
    "    \n",
    "    Saved in triggers_directory :\n",
    "\n",
    "{experience_name}_{link_file_name}_triggers.pkl (dict) : \n",
    "    keys 'indices' --> detected triggers indices, \n",
    "         'duration' --> the stimuli duration, \n",
    "         'trigger_type' --> the detection visual or holo stimuli, \n",
    "         'indice_errors' --> triggers violating sanity check \n",
    "         \n",
    "{experience_name}_{link_file_name}_triggers_data.pkl (numpy array) : raw signal recorded on the trigger channel\n",
    "\n",
    "\"\"\"\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd510d7",
   "metadata": {},
   "source": [
    "### CELL 4 : Plots triggers for sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad66dc09",
   "metadata": {},
   "source": [
    "#### <center>REQUIRES CELL 1 RUN & CELL 3 RUN AT LEAST ONCE FOR THIS EXPERIMENT </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e95f19b",
   "metadata": {},
   "source": [
    "Plots the raw trigger signal with the detected triggers and the errors detected. Independently, plots also the detected triggers, should be a perfect diagonal. Third, plots the number of time points gap to the most common trigger duration (ie theoretical_time_per_frame +- ploted value)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65824ebf",
   "metadata": {},
   "source": [
    "#### <center>/!\\/!\\/!\\ Caution on memory leaks /!\\/!\\/!\\ </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a39ec5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t\t------ End Of Cell ------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Variable\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "#Experiment name\n",
    "exp = params.exp\n",
    "\n",
    "# Optimal threshhold for detecting stimuli onsets varies with the rig\n",
    "threshold  = params.threshold \n",
    "\n",
    "# Directory where plots will be saved\n",
    "output_directory = params.output_directory\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Inputs\n",
    "\"\"\"\n",
    "\n",
    "#Select the recordings number you want to plot (starting from 0)\n",
    "recordings = [0]\n",
    "\n",
    "#Set True if you want the plots to be saved\n",
    "save = False\n",
    "\n",
    "#Define your x-axis ploting window in a tuple (x-min,x-max). Set False to plot the complete data\n",
    "ploting_range = False\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Ploting\n",
    "\"\"\"\n",
    "\n",
    "plt.ioff()\n",
    "plt.close('all')\n",
    "for rec in recordings:\n",
    "    \n",
    "    # Loading data from pickle files created in cell 3\n",
    "    data    = np.array(load_obj(os.path.normpath(os.path.join(params.triggers_directory,'{}_{}_triggers_data.pkl'.format(exp,recording_names[rec])))))\n",
    "    extracted = load_obj(os.path.normpath(os.path.join(params.triggers_directory,'{}_{}_triggers.pkl'.format(exp,recording_names[rec]))))\n",
    "    err = extracted['indice_errors']\n",
    "    indices = extracted['indices']\n",
    "    \n",
    "    # If ploting range is a tuple, reduce the plot to indices between both values of the tuple\n",
    "    if ploting_range :\n",
    "        indices = indices[np.logical_and(indices > ploting_range[0], indices < ploting_range[1])]\n",
    "        data    = data[np.logical_and(np.array(range(len(data))) > ploting_range[0], np.array(range(len(data))) < ploting_range[1])]\n",
    "        err     = err[np.logical_and(err > ploting_range[0], err < ploting_range[1])]\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    # Top plot with raw trigger signal, threshold of detection, detected triggers and wrong triggers\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.title('{}\\n{}'.format(recording_names[rec],link_names[rec]))\n",
    "    \n",
    "    plt.plot(data)\n",
    "    plt.plot(indices,data[indices],'.',markersize=2,zorder=10)\n",
    "\n",
    "    plt.axhline(threshold, color='green')\n",
    "    plt.scatter(err,data[err], color='red', marker='x',zorder = 15)\n",
    "    \n",
    "    # Bottom left plot of triggers indices. Shoule be a perfect diagonal\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.plot(indices)\n",
    "    plt.title('Detected indices')\n",
    "    \n",
    "    # Bottom right plot of relative error gap between detect time of frame and mean frame time\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.plot(np.diff(np.diff(indices)))\n",
    "    try :\n",
    "        plt.title('Duration {} +- error'.format(np.round(np.mean(np.diff(indices)))))\n",
    "    except :\n",
    "        plt.title('Duration {} +- error'.format(\"NOT COMPUTED\"))\n",
    "                  \n",
    "    plt.tight_layout()\n",
    "    plt.show(block = False)\n",
    "    \n",
    "    # Saving plot if needed\n",
    "    if save:\n",
    "        fig_name = os.path.join(output_directory,r'{}_{}.png'.format(recording_names[rec],link_names[rec]))\n",
    "        plt.savefig(fig_name)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Output\n",
    "    \n",
    "    if save == True\n",
    "    \n",
    "    {recording_file_name}_{link_file_name}.png : Plots for a given recording file\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97874f0c",
   "metadata": {},
   "source": [
    "### Cell 5 : Dead times file creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b129352c",
   "metadata": {},
   "source": [
    "#### <center>REQUIRES CELL 1 RUN & CELL 3 RUN AT LEAST ONCE FOR THIS EXPERIMENT </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943a1311",
   "metadata": {},
   "source": [
    "Run minimal sanity check on visual triggers and create the dead times in sec for holographic stimuli. If you only have visual triggers, running this cell isn't mandatory, it only provides a repeated sanity check for visual stims..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19117ee9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording 0 :\t1-Checkerboard_40hz_12px_60sq.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Recording 1 :\t2-Chirp_50hz.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Recording 2 :\t3-DG_50hz.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Recording 3 :\t3-DG_50hz_bis.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Recording 4 :\t4-Moving_disks_r7_40hz.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Recording 5 :\t5-Moving_disks_r10_40hz.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Recording 6 :\t6-Moving_disks_r14_40hz.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Recording 7 :\t7-Chirp_End_50hz.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Recording 8 :\t8-Checkerboard_End_40hz_12px_60sq.raw\n",
      "No sanity check performed, only 1 trigger detected. Is threshold correct ?\n",
      "\n",
      "\n",
      "Writting dead times file for 0 holographic recordings...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Variable\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "#name of your experiment for saving the triggers\n",
    "exp = params.exp\n",
    "\n",
    "#The folder in which you saved your triggers\n",
    "triggers_directory = params.triggers_directory\n",
    "\n",
    "#The folder containing raw recording files\n",
    "recoding_directory = params.recording_directory\n",
    "\n",
    "# Directory where dead_times file will be saved\n",
    "output_directory = params.output_directory\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "\n",
    "rec_onsets    = recording_onsets(recording_names, path = recoding_directory)  \n",
    "\n",
    "holo_onsets   = []\n",
    "holo_triggers = []\n",
    "for rec in range(len(recording_names)):\n",
    "    \n",
    "    #Loading data\n",
    "    trig_data = load_obj(os.path.normpath(os.path.join(params.triggers_directory,'{}_{}_triggers.pkl'.format(exp,recording_names[rec]))))\n",
    "    \n",
    "    \n",
    "    if trig_data['trigger_type']=='holo':\n",
    "        #If recording was detected as holographic\n",
    "        print('Recording {} detected as holographic :\\t{}'.format(rec, recording_names[rec]))\n",
    "        holo_onsets.append(rec_onsets[recording_names[rec]])\n",
    "        holo_triggers.append(trig_data['indices'])\n",
    "        print('Number of triggers to be added to dead times file : {}'.format(len(trig_data['indices'])))\n",
    "        \n",
    "    else:\n",
    "        #Otherwise it is considered as visual\n",
    "        print('Recording {} :\\t{}'.format(rec, recording_names[rec]))\n",
    "        err = run_minimal_sanity_check(trig_data['indices'])    \n",
    "    print('\\n')\n",
    "\n",
    "print('Writting dead times file for {} holographic recordings...'.format(len(holo_triggers)))\n",
    "#Writting .dead file using utils function\n",
    "write_dead_times_file(holo_triggers,holo_onsets, output_directory)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Ploting\n",
    "\"\"\"\n",
    "\n",
    "#Potting once more the recordings onsets similarly to cell 2\n",
    "ticks=[]\n",
    "plt.ioff()\n",
    "plt.close('all')\n",
    "plt.figure() \n",
    "for rec in range(len(recording_names)):\n",
    "    plt.axhline(rec_onsets[recording_names[rec]]/params.fs/60)\n",
    "    ticks.append(rec_onsets[recording_names[rec]]/params.fs/60)\n",
    "    \n",
    "plt.yticks(ticks)\n",
    "plt.title('Recording starting time')\n",
    "plt.ylabel('Minutes')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Output\n",
    "    \n",
    "    {recording_file_name}_dead_times.dead : dead time file given times to exclude in spyking circus\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e0470",
   "metadata": {},
   "source": [
    "# <center>/!\\/!\\/!\\ Run this after the sorting /!\\/!\\/!\\ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59361bc0",
   "metadata": {},
   "source": [
    "### Cell 6 : Creating all clusters rasters plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa73fb",
   "metadata": {},
   "source": [
    "#### <center>REQUIRES CELL 1 RUN</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde0d8e5",
   "metadata": {},
   "source": [
    "Run after automatic sorting to help with manual sorting. Saves all automatic clusters' rasters on the repeated checherboard in the phy directory. You can run this several times during sorting to make new clusters rasters. Can take few sec per cluster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a54aae9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spike extraction: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10bee6df8344abcadf742594c05c1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23011797 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1516bb33eac2474c95c12ffe753ecde8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Raster plots : \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d496fb8fea145459c244ff7aec0ea0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving rasters plots of all clusters :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4122ba2ae9874113a6d256ed07072fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t\t------ End Of Cell ------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Variable\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "#length of each sequence composed of half repeated sequence and half random sequence\n",
    "\n",
    "nb_frames_by_sequence = params.nb_frames_by_sequence\n",
    "\n",
    "# Name of your experiment\n",
    "exp = params.exp\n",
    "\n",
    "#Path to the folder with the phy output\n",
    "phy_directory = params.phy_directory\n",
    "\n",
    "#Path to raw recording files\n",
    "recoding_directory = params.recording_directory\n",
    "\n",
    "#Frequency of sampling of the mea\n",
    "fs = params.fs\n",
    "\n",
    "\"\"\"\n",
    "    Input\n",
    "\"\"\"\n",
    "#Number of the checkerboard recording of choice (start from zero)\n",
    "check_recording_number = 0\n",
    "\n",
    "#Checkerboard frequency in Hz\n",
    "stimulus_frequency = 30\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "###################################\n",
    "#### Loading phy clusters info ####\n",
    "###################################\n",
    "\n",
    "\n",
    "\n",
    "rec_onsets = recording_onsets(recording_names, path = recording_directory)  \n",
    "\n",
    "# Get cells index and number\n",
    "cluster_number , good_clusters = extract_cluster_groups(phy_directory)\n",
    "\n",
    "# Extract the spike times from the spike sorting files. This can take a few minutes.\n",
    "print('Spike extraction: ')\n",
    "all_spike_times = extract_all_spike_times_from_phy(phy_directory)\n",
    "\n",
    "# create a dictionary with another dictionary for each cluster\n",
    "all_neurons_data = split_spikes_by_recording(all_spike_times, cluster_number, rec_onsets)\n",
    "\n",
    "\n",
    "#############################\n",
    "#### Making raster plots ####\n",
    "#############################\n",
    "\n",
    "checkerboard_name = recording_names[check_recording_number]\n",
    "\n",
    "checkerboard_spikes = get_recording_spikes(checkerboard_name, all_neurons_data)\n",
    "\n",
    "trig_data = load_obj(os.path.normpath(os.path.join(params.triggers_directory,'{}_{}_triggers.pkl'.format(exp,checkerboard_name))))\n",
    "triggers = trig_data['indices']/fs\n",
    "raster_data = {}\n",
    "\n",
    "print('Building Raster plots : ')\n",
    "for (cell_nb, spike_times) in tqdm(checkerboard_spikes.items()):\n",
    "    # Align triggers and spike times\n",
    "    aligned_triggers, aligned_spike_times = align_triggers_spikes(triggers, spike_times)\n",
    "    \n",
    "    # Get rasters on repeated sequence\n",
    "    raster_data[cell_nb] = build_rasters(aligned_spike_times, aligned_triggers, stim_frequency = stimulus_frequency)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Saving\n",
    "\"\"\"\n",
    "\n",
    "#Save all clusters rasters plots    \n",
    "fig_directory = os.path.normpath(os.path.join(phy_directory,r'clusters_rasters_{}'.format(check_recording_number)))\n",
    "if not os.path.isdir(fig_directory): os.makedirs(fig_directory)\n",
    "\n",
    "    \n",
    "print(\"Saving rasters plots of all clusters :\")\n",
    "for cell_nb in tqdm(raster_data.keys()):\n",
    "    fig, axs = plt.subplots(nrows = 2,ncols = 1, sharex=True, gridspec_kw={'height_ratios': [3, 1]}, figsize=(10,10))\n",
    "\n",
    "    plt.suptitle(f'Cell {cell_nb}')\n",
    "\n",
    "    ax_rast = axs[0]\n",
    "    ax_rast.eventplot(raster_data[cell_nb][\"spike_trains\"])\n",
    "    ax_rast.set(title = \"Raster plot\", ylabel='N Repetitions')\n",
    "\n",
    "    ax_psth = axs[1]\n",
    "    width = (raster_data[cell_nb][\"repeated_sequences_times\"][0][0]/600)\n",
    "    ax_psth.bar(np.linspace(0,raster_data[cell_nb][\"repeated_sequences_times\"][0][0],int(nb_frames_by_sequence/2))+width/2, raster_data[cell_nb][\"psth\"], width=1.3*width)\n",
    "    ax_psth.set(xlabel='Time in sec', ylabel='Firing rate (spikes/s)')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig_file = os.path.normpath(os.path.join(fig_directory,f'Cluster_{cell_nb}.png'))\n",
    "    plt.savefig(fig_file, dpi=fig.dpi)\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "\"\"\"\n",
    "    Output\n",
    "    \n",
    "    Save :\n",
    "    \n",
    "    \"\"{phy_directory}/clusters_rasters/Cluster_{Cluster_number}.png\" for each found clusters in phy's files\n",
    "\"\"\"    \n",
    "\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84f6b6",
   "metadata": {},
   "source": [
    "### Cell 7 : Extract data per neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76ed40b",
   "metadata": {},
   "source": [
    "#### <center>REQUIRES CELL 1 RUN</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a953b24",
   "metadata": {},
   "source": [
    "Extract all data from phy numpy variables. Create&save a dictionnary containg spikes times in sec for each neuron splited by recording. Depending on your experiment, this can take severeal minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ead816c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 339 good clusters (578 clusters in total)\n",
      "\n",
      "Spike extraction: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30a5e1bcadb4d19a850270bffcb7355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23011797 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Spike division in recordings per neuron:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80aeff43aa946a88ad454a0e9c8cb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/339 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t\t------ End Of Cell ------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Variable\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "# Name of your experiment\n",
    "exp = params.exp\n",
    "\n",
    "#Path to the folder with the phy output\n",
    "phy_directory = params.phy_directory\n",
    "\n",
    "#Path to where data should be saved\n",
    "output_directory = params.output_directory\n",
    "\n",
    "#Path to rax recording files\n",
    "recoding_directory = params.recording_directory\n",
    "\n",
    "#Frequency of sampling of the mea\n",
    "fs = params.fs\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "\n",
    "rec_onsets    = recording_onsets(recording_names, path = recording_directory)  \n",
    "\n",
    "# Get cells index and number\n",
    "cluster_number , good_clusters = extract_cluster_groups(phy_directory)\n",
    "print(\"There are {} good clusters ({} clusters in total)\\n\".format(len(good_clusters), len(cluster_number)))\n",
    "\n",
    "\n",
    "# Extract the spike times from the spike sorting files. This can take a few minutes.\n",
    "print('Spike extraction: ')\n",
    "all_spike_times = extract_all_spike_times_from_phy(phy_directory)\n",
    "\n",
    "print('\\n')\n",
    "print('Spike division in recordings per neuron:')\n",
    "# create a dictionary with another dictionary for each good cluster\n",
    "good_data = split_spikes_by_recording(all_spike_times, good_clusters, rec_onsets)\n",
    "\n",
    "\n",
    "# Save the spike data. This can take a few minutes.\n",
    "good_data_file_name = os.path.join(output_directory,r'{}_fullexp_neurons_data.pkl'.format(exp))\n",
    "save_obj(good_data,good_data_file_name)\n",
    "\n",
    "\"\"\"\n",
    "    Output\n",
    "    \n",
    "    data (dict) : key 'cluster_id' --> (dict) key 'recording_name' --> This neuron & this recording spikes times in sec\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
