{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad02697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing spike interface, this may take a while...\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "\n",
    "print(\"Importing spike interface, this may take a while...\")\n",
    "import spikeinterface.full as si\n",
    "import docker\n",
    "print(\"Done...\")\n",
    "import scipy\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import probeinterface as pi\n",
    "from probeinterface.plotting import plot_probe_group, plot_probe\n",
    "\n",
    "# Load probe\n",
    "probe = pi.read_prb('mcs_256_30_8iR_ITO.prb')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('qt5agg')\n",
    "\n",
    "from utils import *         # Local file containing all the functions that we need\n",
    "import params               # Parameters file. You should tune it for your own experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8107d8fe",
   "metadata": {},
   "source": [
    "### Cell 1 : Open files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8f4da5",
   "metadata": {},
   "source": [
    "Open all recordings before filtering + sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f44c855",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of recordings: 6\n",
      "\n",
      "\n",
      "Check that recordings lengths are consistent with recording names\n",
      "\n",
      "30 minutes\t--->\t0 : checkerboard -> OK\n",
      "11 minutes\t--->\t1 : chirp -> OK\n",
      "7 minutes\t--->\t2 : drifting_gratings -> OK\n",
      "50 minutes\t--->\t3 : white_noise_1d -> OK\n",
      "37 minutes\t--->\t4 : moving_bars -> OK\n",
      "119 minutes\t--->\t5 : perturbed_moving_bar -> OK\n",
      "\n",
      "\t\t\t------ End Of Cell ------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Variables\n",
    "    \n",
    "    DO NOT CHANGE VALUES HERE UNLESS DEBUG/SPECIFIC USE\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "#Link to the actual raw files from the recording listed in the input_file\n",
    "recording_directory = params.recording_directory\n",
    "\n",
    "#Loading raw recording files names\n",
    "recording_names = params.recording_names\n",
    "\n",
    "# number of triggers samples acquired per second\n",
    "fs         = params.fs\n",
    "\n",
    "Nchannels  = params.nb_channels                #256 for standard MEA, 17 for MEA1 Polychrome\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "\n",
    "recording_names = [rec.replace('.raw','') for rec in recording_names]\n",
    "rec_it = recording_names[:]+['end']\n",
    "print('Number of recordings: {}\\n'.format(len(recording_names)))\n",
    "\n",
    "#getting onset for next prints\n",
    "onsets = {}\n",
    "onsets = recording_onsets(recording_names, path = recording_directory)\n",
    "\n",
    "#Opening files\n",
    "print('\\nCheck that recordings lengths are consistent with recording names\\n') \n",
    "\n",
    "\n",
    "for i in range(len(rec_it)-1):    \n",
    "    print(\"{} minutes\\t--->\\t{} : {} -> OK\".format(int((onsets[rec_it[i+1]]-onsets[rec_it[i]])/params.fs/60), i, rec_it[i]))\n",
    "\n",
    "\n",
    "\"\"\"Output :\n",
    "\n",
    "Var :\n",
    "recordings_names : Ordered list of stimuli names played during experiment\n",
    "\"\"\"   \n",
    "\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ecdb2a",
   "metadata": {},
   "source": [
    "### Cell 2 : Extract the triggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b9255e",
   "metadata": {},
   "source": [
    "#### <center>REQUIRES CELL 1 RUN</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb53ca0",
   "metadata": {},
   "source": [
    "Extract triggers from either the visual or holo trigger channel. Automatic detection of Holographic recording. Check that the detection is perform on the right files. Perform triggers sanity checks for visual stimumi. You can plot them later on cell 4. Can take up to more than 1h to run all recordings depending on your experiment length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "173c010d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------   Processing recording 1 out of 6   -------------\n",
      "\n",
      "The triggers are extracted from the sorting file:\tcheckerboard.raw\n",
      "and the results will be saved at:\t\t\t/media/guiglaz/DATA1/20230824_tbt_1/Analysis/triggers/20230824_tbt_1_checkerboard_triggers.pkl\n",
      "Trigers already extracted previously. Write again files files? Type Y to do so :\n",
      "\n",
      "\n",
      "-------------   Processing recording 2 out of 6   -------------\n",
      "\n",
      "The triggers are extracted from the sorting file:\tchirp.raw\n",
      "and the results will be saved at:\t\t\t/media/guiglaz/DATA1/20230824_tbt_1/Analysis/triggers/20230824_tbt_1_chirp_triggers.pkl\n",
      "Trigers already extracted previously. Write again files files? Type Y to do so :\n",
      "\n",
      "\n",
      "-------------   Processing recording 3 out of 6   -------------\n",
      "\n",
      "The triggers are extracted from the sorting file:\tdrifting_gratings.raw\n",
      "and the results will be saved at:\t\t\t/media/guiglaz/DATA1/20230824_tbt_1/Analysis/triggers/20230824_tbt_1_drifting_gratings_triggers.pkl\n",
      "Trigers already extracted previously. Write again files files? Type Y to do so :\n",
      "\n",
      "\n",
      "-------------   Processing recording 4 out of 6   -------------\n",
      "\n",
      "The triggers are extracted from the sorting file:\twhite_noise_1d.raw\n",
      "and the results will be saved at:\t\t\t/media/guiglaz/DATA1/20230824_tbt_1/Analysis/triggers/20230824_tbt_1_white_noise_1d_triggers.pkl\n",
      "Trigers already extracted previously. Write again files files? Type Y to do so :\n",
      "\n",
      "\n",
      "-------------   Processing recording 5 out of 6   -------------\n",
      "\n",
      "The triggers are extracted from the sorting file:\tmoving_bars.raw\n",
      "and the results will be saved at:\t\t\t/media/guiglaz/DATA1/20230824_tbt_1/Analysis/triggers/20230824_tbt_1_moving_bars_triggers.pkl\n",
      "Trigers already extracted previously. Write again files files? Type Y to do so :\n",
      "\n",
      "\n",
      "-------------   Processing recording 6 out of 6   -------------\n",
      "\n",
      "The triggers are extracted from the sorting file:\tperturbed_moving_bar.raw\n",
      "and the results will be saved at:\t\t\t/media/guiglaz/DATA1/20230824_tbt_1/Analysis/triggers/20230824_tbt_1_perturbed_moving_bar_triggers.pkl\n",
      "Trigers already extracted previously. Write again files files? Type Y to do so :\n",
      "\n",
      "\n",
      "\t\t\t------ End Of Cell ------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Variable\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "#name of your experiment for saving the triggers\n",
    "exp = params.exp\n",
    "\n",
    "# select MEA (3=2p room) (4=MEA1 Polycrhome)\n",
    "MEA = params.MEA                       \n",
    "\n",
    "#the optimal threshhold for detecting stimuli onsets varies with the rig\n",
    "threshold  = params.threshold           \n",
    "\n",
    "Nchannels  = params.nb_channels                #256 for standard MEA, 17 for MEA1 Polychrome\n",
    "\n",
    "# number of triggers samples acquired per second\n",
    "fs         = params.fs\n",
    "\n",
    "#The folder in which you want your triggers to be saved \n",
    "triggers_directory = params.triggers_directory\n",
    "\n",
    "#Channel recording triggers in case of holographic stimuli\n",
    "holo_channel_id   = params.holo_channel_id\n",
    "\n",
    "#Channel recording triggers in case of visual stimuli\n",
    "visual_channel_id = params.visual_channel_id \n",
    "\n",
    "\"\"\"\n",
    "    Inputs\n",
    "\"\"\"\n",
    "\n",
    "#you can decide here to extract the triggers only for some recordings. List their indexes here (starting from 0).\n",
    "select_rec = []    # do only measurement N, put [] or the complet list to call all of them\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "\n",
    "for rec in range(len(recording_names)):\n",
    "    if select_rec:\n",
    "        if rec not in select_rec: continue\n",
    "    \n",
    "    print('\\n-------------   Processing recording {} out of {}   -------------\\n'.format(rec+1,len(recording_names)))\n",
    "\n",
    "    # Creating all files path\n",
    "    input_file    = os.path.join(recording_directory,recording_names[rec]+'.raw')\n",
    "    trigger_file  = os.path.join(triggers_directory,'{}_{}_triggers.pkl'.format(exp,recording_names[rec]))\n",
    "    data_file     = os.path.join(triggers_directory,'{}_{}_triggers_data.pkl'.format(exp,recording_names[rec]))\n",
    "    \n",
    "    print('The triggers are extracted from the sorting file:\\t{}\\nand the results will be saved at:\\t\\t\\t{}'.format(recording_names[rec]+'.raw',trigger_file))\n",
    "    if os.path.exists(data_file):\n",
    "        if (str(input('Trigers already extracted previously. Write again files files? Type Y to do so :\\n')) != 'Y') : continue\n",
    "        \n",
    "    if is_holographic_rec(input_file): \n",
    "        #in this case the stimulus was holograpic\n",
    "        print(r\" /!\\ HOLOGRAPHIC Recording /!\\ \")\n",
    "        channel_id   = holo_channel_id\n",
    "        trigger_type = 'holo'\n",
    "        onsets_file  = os.path.join(triggers_directory,'{}_{}_laser_onsets.npy'.format(exp,recording_names[rec]))\n",
    "        offsets_file  = os.path.join(triggers_directory,'{}_{}_laser_offsets.npy'.format(exp,recording_names[rec]))\n",
    "    else: \n",
    "        #in this other case the stimulus was visual\n",
    "        print(r\" /!\\ VISUAL Recording /!\\ \")\n",
    "        channel_id   = visual_channel_id        \n",
    "        trigger_type = 'visual'\n",
    "        \n",
    "    #Processing of data calling utils functions\n",
    "    print(\"Loading Data...\")\n",
    "    channel_id   = visual_channel_id        \n",
    "    trigger_type = 'visual'      \n",
    "\n",
    "    data, t_tot    = load_data(input_file, channel_id = channel_id )  #MANUALLY CHANGE HERE IF THE CHANNEL IS \n",
    "                                                                     #AUTHOMATICALLY MISDETECTED. IF SO IT SHOULD \n",
    "                                                                    #BE BECAUSE OF ALIASING OR BAD TRIGGER QUALITY\n",
    "    indices        = detect_onsets(data,threshold)\n",
    "    indices_errors = run_minimal_sanity_check(indices, stim_type = trigger_type)\n",
    "    \n",
    "    #Saving data using utils function save_obj\n",
    "    save_obj({'indices':indices,'duration':t_tot,'trigger_type':trigger_type,'indice_errors':indices_errors}, trigger_file )\n",
    "    save_obj(data,data_file)\n",
    "    \n",
    "\n",
    "    if trigger_type == 'holo':\n",
    "        save_obj(indices, onsets_file)\n",
    "    \n",
    "        offsets = detect_offsets(data)\n",
    "        save_obj(offsets, offsets_file)    \n",
    "        \n",
    "\"\"\"\n",
    "    Output\n",
    "    \n",
    "    Saved in triggers_directory :\n",
    "\n",
    "{experience_name}_{link_file_name}_triggers.pkl (dict) : \n",
    "    keys 'indices' --> detected triggers indices, \n",
    "         'duration' --> the stimuli duration, \n",
    "         'trigger_type' --> the detection visual or holo stimuli, \n",
    "         'indice_errors' --> triggers violating sanity check \n",
    "         \n",
    "{experience_name}_{link_file_name}_triggers_data.pkl (numpy array) : raw signal recorded on the trigger channel\n",
    "\"\"\"\n",
    "\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c02e8f5",
   "metadata": {},
   "source": [
    "### CELL 3 : Plots triggers for sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3010467",
   "metadata": {},
   "source": [
    "#### <center>REQUIRES CELL 1 RUN & CELL 2 RUN AT LEAST ONCE FOR THIS EXPERIMENT </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350a6078",
   "metadata": {},
   "source": [
    "Plots the raw trigger signal with the detected triggers and the errors detected. Independently, plots also the detected triggers, should be a perfect diagonal. Third, plots the number of time points gap to the most common trigger duration (ie theoretical_time_per_frame +- ploted value)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b877cd",
   "metadata": {},
   "source": [
    "#### <center>/!\\/!\\/!\\ Caution on memory leaks /!\\/!\\/!\\ </center> (if you know a solution please let me know)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b517c9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : checkerboard\n",
      "1 : chirp\n",
      "2 : drifting_gratings\n",
      "3 : white_noise_1d\n",
      "4 : moving_bars\n",
      "5 : perturbed_moving_bar\n",
      "\n",
      "Select recording : 0\n",
      "\n",
      "\t\t\t------ End Of Cell ------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Variable\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "#Experiment name\n",
    "exp = params.exp\n",
    "\n",
    "# Optimal threshhold for detecting stimuli onsets varies with the rig\n",
    "threshold  = params.threshold\n",
    "\n",
    "# Directory where plots will be saved\n",
    "output_directory = params.output_directory\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Inputs\n",
    "\"\"\"\n",
    "\n",
    "#Set True if you want the plots to be saved\n",
    "save = False\n",
    "\n",
    "#Define your x-axis ploting window in a tuple (x-min,x-max). Set False to plot the complete data\n",
    "ploting_range = False\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Ploting\n",
    "\"\"\"\n",
    "\n",
    "print(*['{} : {}'.format(i,recording_name) for i, recording_name in enumerate(recording_names)], sep=\"\\n\")\n",
    "recordings = [int(rec_id) for rec_id in input(\"\\nSelect recording : \").split()]\n",
    "\n",
    "\n",
    "plt.close('all')\n",
    "gc.collect()\n",
    "plot_idx = 0\n",
    "\n",
    "for rec in recordings:\n",
    "    plot_idx+=1\n",
    "    # Loading data from pickle files created in cell 3\n",
    "    data    = np.array(load_obj(os.path.normpath(os.path.join(params.triggers_directory,'{}_{}_triggers_data.pkl'.format(exp,recording_names[rec])))))\n",
    "    extracted = load_obj(os.path.normpath(os.path.join(params.triggers_directory,'{}_{}_triggers.pkl'.format(exp,recording_names[rec]))))\n",
    "    err = extracted['indice_errors']\n",
    "    indices = extracted['indices']\n",
    "    rec_type = extracted[\"trigger_type\"]\n",
    "    \n",
    "    # If ploting range is a tuple, reduce the plot to indices between both values of the tuple\n",
    "    if ploting_range :\n",
    "        indices = indices[np.logical_and(indices > ploting_range[0], indices < ploting_range[1])]\n",
    "        data    = data[np.logical_and(np.array(range(len(data))) > ploting_range[0], np.array(range(len(data))) < ploting_range[1])]\n",
    "        err     = err[np.logical_and(err > ploting_range[0], err < ploting_range[1])]\n",
    "    \n",
    "    plt.figure(\"Trigger sanity check {}\".format(plot_idx))\n",
    "    \n",
    "    # Top plot with raw trigger signal, threshold of detection, detected triggers and wrong triggers\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.title('{}\\n{} channel'.format(recording_names[rec],rec_type))\n",
    "    \n",
    "    plt.plot(np.linspace(0,len(data)/fs,len(data) ),data)\n",
    "    plt.plot(indices/fs,data[indices],'.',markersize=2,zorder=10)\n",
    "\n",
    "    plt.axhline(threshold, color='green')\n",
    "    plt.scatter(err/fs,data[err], color='red', marker='x',zorder = 15)\n",
    "    \n",
    "    # Bottom left plot of triggers indices. Shoule be a perfect diagonal\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.plot(indices)\n",
    "    plt.title('Detected indices')\n",
    "    \n",
    "    # Bottom right plot of relative error gap between detect time of frame and mean frame time\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.plot(np.diff(np.diff(indices)))\n",
    "    try :\n",
    "        plt.title('Duration {} +- error'.format(np.round(np.mean(np.diff(indices)))))\n",
    "    except :\n",
    "        plt.title('Duration {} +- error'.format(\"NOT COMPUTED\"))\n",
    "                  \n",
    "    plt.tight_layout()\n",
    "    plt.show(block = False)\n",
    "    \n",
    "    # Saving plot if needed\n",
    "    if save:\n",
    "        fig_name = os.path.join(output_directory,r'{}_{}.png'.format(recording_names[rec],link_names[rec]))\n",
    "        plt.savefig(fig_name)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Output\n",
    "    \n",
    "    if save == True\n",
    "    \n",
    "    {recording_file_name}_{link_file_name}.png : Plots for a given recording file\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95130f8f",
   "metadata": {},
   "source": [
    "### Cell 4 : Preprocess all recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e2b314",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkerboard \n",
      " Opened BinaryRecordingExtractor: 256 channels - 1 segments - 20.0kHz - 1816.300s\n",
      "  file_paths: ['/media/guiglaz/DATA1/20230824_tbt_1/RAW_Files/checkerboard.raw']\n",
      "--> Probe attached ChannelSliceRecording: 252 channels - 1 segments - 20.0kHz - 1816.300s\n",
      "--> Filtered bandpass BandpassFilterRecording: 252 channels - 1 segments - 20.0kHz - 1816.300s\n",
      "--> Median removed CommonReferenceRecording: 252 channels - 1 segments - 20.0kHz - 1816.300s\n",
      "\n",
      "\n",
      "chirp \n",
      " Opened BinaryRecordingExtractor: 256 channels - 1 segments - 20.0kHz - 663.000s\n",
      "  file_paths: ['/media/guiglaz/DATA1/20230824_tbt_1/RAW_Files/chirp.raw']\n",
      "--> Probe attached ChannelSliceRecording: 252 channels - 1 segments - 20.0kHz - 663.000s\n",
      "--> Filtered bandpass BandpassFilterRecording: 252 channels - 1 segments - 20.0kHz - 663.000s\n",
      "--> Median removed CommonReferenceRecording: 252 channels - 1 segments - 20.0kHz - 663.000s\n",
      "\n",
      "\n",
      "drifting_gratings \n",
      " Opened BinaryRecordingExtractor: 256 channels - 1 segments - 20.0kHz - 423.500s\n",
      "  file_paths: ['/media/guiglaz/DATA1/20230824_tbt_1/RAW_Files/drifting_gratings.raw']\n",
      "--> Probe attached ChannelSliceRecording: 252 channels - 1 segments - 20.0kHz - 423.500s\n",
      "--> Filtered bandpass BandpassFilterRecording: 252 channels - 1 segments - 20.0kHz - 423.500s\n",
      "--> Median removed CommonReferenceRecording: 252 channels - 1 segments - 20.0kHz - 423.500s\n",
      "\n",
      "\n",
      "white_noise_1d \n",
      " Opened BinaryRecordingExtractor: 256 channels - 1 segments - 20.0kHz - 3014.200s\n",
      "  file_paths: ['/media/guiglaz/DATA1/20230824_tbt_1/RAW_Files/white_noise_1d.raw']\n",
      "--> Probe attached ChannelSliceRecording: 252 channels - 1 segments - 20.0kHz - 3014.200s\n",
      "--> Filtered bandpass BandpassFilterRecording: 252 channels - 1 segments - 20.0kHz - 3014.200s\n",
      "--> Median removed CommonReferenceRecording: 252 channels - 1 segments - 20.0kHz - 3014.200s\n",
      "\n",
      "\n",
      "moving_bars \n",
      " Opened BinaryRecordingExtractor: 256 channels - 1 segments - 20.0kHz - 2273.200s\n",
      "  file_paths: ['/media/guiglaz/DATA1/20230824_tbt_1/RAW_Files/moving_bars.raw']\n",
      "--> Probe attached ChannelSliceRecording: 252 channels - 1 segments - 20.0kHz - 2273.200s\n",
      "--> Filtered bandpass BandpassFilterRecording: 252 channels - 1 segments - 20.0kHz - 2273.200s\n",
      "--> Median removed CommonReferenceRecording: 252 channels - 1 segments - 20.0kHz - 2273.200s\n",
      "\n",
      "\n",
      "perturbed_moving_bar \n",
      " Opened BinaryRecordingExtractor: 256 channels - 1 segments - 20.0kHz - 7195.500s\n",
      "  file_paths: ['/media/guiglaz/DATA1/20230824_tbt_1/RAW_Files/perturbed_moving_bar.raw']\n",
      "--> Probe attached ChannelSliceRecording: 252 channels - 1 segments - 20.0kHz - 7195.500s\n",
      "--> Filtered bandpass BandpassFilterRecording: 252 channels - 1 segments - 20.0kHz - 7195.500s\n",
      "--> Median removed CommonReferenceRecording: 252 channels - 1 segments - 20.0kHz - 7195.500s\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t------ End Of Cell ------\n"
     ]
    }
   ],
   "source": [
    "exp = params.exp\n",
    "fs = params.fs\n",
    "\n",
    "#The folder in which you want your triggers to be saved \n",
    "triggers_directory = params.triggers_directory\n",
    "\n",
    "recordings = {}\n",
    "for recording_name in recording_names:\n",
    "    recordings[recording_name] = {}\n",
    "    \n",
    "    extracted = load_obj(os.path.normpath(os.path.join(params.triggers_directory,'{}_{}_triggers.pkl'.format(exp,recording_name))))\n",
    "    trigger_type = extracted['trigger_type']\n",
    "    \n",
    "    # Open file\n",
    "    recordings[recording_name]['raw'] = si.read_binary(os.path.join(recording_directory,recording_name+'.raw'), sampling_frequency=fs, num_chan=Nchannels, dtype='uint16')\n",
    "    print(f\"{recording_name} \\n Opened\", end=' ')\n",
    "    print(recordings[recording_name]['raw'])\n",
    "    #Set probe to .prb file in the folder\n",
    "    recordings[recording_name]['raw'] = recordings[recording_name]['raw'].set_probegroup(probe)\n",
    "    print(\"--> Probe attached\",end=' ')\n",
    "    print(recordings[recording_name]['raw'])\n",
    "    # Filter recordings\n",
    "    recordings[recording_name]['si_filtered'] = si.bandpass_filter(recordings[recording_name]['raw'], dtype=\"float32\")\n",
    "    print(\"--> Filtered bandpass\",end=' ')\n",
    "    print(recordings[recording_name]['si_filtered'])\n",
    "    # Remove median for all recordings\n",
    "    recordings[recording_name]['si_filtered_medianremoved'] = si.common_reference(recordings[recording_name]['si_filtered'])\n",
    "    print(\"--> Median removed\", end=' ')\n",
    "    print(recordings[recording_name]['si_filtered_medianremoved'])\n",
    "    \n",
    "    if trigger_type == 'holo':       \n",
    "        #Onsets and offsets loading\n",
    "        stim_onsets = load_obj(os.path.join(triggers_directory,'{}_{}_laser_onsets.npy'.format(exp,recording_name)))\n",
    "        stim_offsets = load_obj(os.path.join(triggers_directory,'{}_{}_laser_offsets.npy'.format(exp,recording_name)))\n",
    "\n",
    "        #Computing times of laser bims\n",
    "        times = np.sort(np.concatenate((stim_onsets, stim_offsets)))\n",
    "    \n",
    "        #Removing artefacts\n",
    "        recordings[recording_name]['si_cleaned_zeros'] = si.remove_artifacts(recordings[recording_name]['si_filtered_medianremoved'], \n",
    "                                                               list_triggers=[list(times)], \n",
    "                                                               ms_before=5, \n",
    "                                                               ms_after=5, \n",
    "                                                               mode='zeros')\n",
    "        print(\"--> laser on and off times set to 0\") \n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a82fd3",
   "metadata": {},
   "source": [
    "### Visualize artefacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f5303",
   "metadata": {},
   "source": [
    "Helps you visualize the artefacts once removed. If it breaks with an IndexError, you may have too much or too few triggers. It may not be an issue for you if you accept to put more parts of the recording to 0. If it is you have to rewrite the files laser_onsets and laser_offsets in the trigger folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9116d1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "You have a visual recording only. You don't have laser artefacts in your recording. Proceed with the rest of the notebook",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m params\u001b[38;5;241m.\u001b[39mMEA \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have a visual recording only. You don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have laser artefacts in your recording. Proceed with the rest of the notebook\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#import pylab as plt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m exp \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mexp\n",
      "\u001b[0;31mAssertionError\u001b[0m: You have a visual recording only. You don't have laser artefacts in your recording. Proceed with the rest of the notebook"
     ]
    }
   ],
   "source": [
    "assert params.MEA == 3, \"You have a visual recording only. You don't have laser artefacts in your recording. Proceed with the rest of the notebook\"\n",
    "\n",
    "#import pylab as plt\n",
    "exp = params.exp\n",
    "\n",
    "frames_path = params.frames_path\n",
    "fs = params.fs\n",
    "\n",
    "waveform_id = 1 #waveform patern number\n",
    "elec = 136  #electrode number\n",
    "\n",
    "print(*['{} : {}'.format(i,recording_name) for i, recording_name in enumerate(recordings.keys())], sep=\"\\n\")\n",
    "recording_name = recording_names[int(input(\"\\nSelect holographic recording : \"))]\n",
    "\n",
    "\n",
    "frames_folder_files = [f for f in os.listdir(frames_path) if os.path.isfile(os.path.join(frames_path, f))]\n",
    "print(*['{} : {}'.format(i,frame_file) for i, frame_file in enumerate(frames_folder_files)], sep=\"\\n\")\n",
    "frame_name = frames_folder_files[int(input(f\"\\nSelect the DH_frames file for the recording {recording_name} \\n\"))]\n",
    "\n",
    "#Frames loading\n",
    "frames = scipy.io.loadmat(os.path.join(frames_path, frame_name))\n",
    "spot_order = np.array([i[0] for i in frames['OrderFrames']])\n",
    "\n",
    "#Onsets and offsets loading\n",
    "onsets_file  = os.path.join(triggers_directory,'{}_{}_laser_onsets.npy'.format(exp,recording_name))\n",
    "offsets_file  = os.path.join(triggers_directory,'{}_{}_laser_offsets.npy'.format(exp,recording_name))\n",
    "\n",
    "stim_onsets = load_obj(onsets_file)\n",
    "stim_offsets = load_obj(offsets_file)\n",
    "\n",
    "#Computing times of laser bims\n",
    "times = np.concatenate((stim_onsets, stim_offsets))\n",
    "labels = np.concatenate((spot_order, spot_order+max(spot_order)))\n",
    "idx = np.argsort(times)\n",
    "times = times[idx]\n",
    "labels = labels[idx]\n",
    "\n",
    "sorting = si.NumpySorting.from_times_labels(times, labels, sampling_frequency=fs)\n",
    "sorting = sorting.save()\n",
    "\n",
    "\n",
    "waveforms = {}\n",
    "waveforms['si_filtered_medianremoved'] = si.extract_waveforms(recordings[recording_name]['si_filtered_medianremoved'], \n",
    "                             sorting, ms_before=10, ms_after=10, mode='memory',\n",
    "     n_jobs=10, allow_unfiltered=True, chunk_memory=\"10M\", overwrite=True, sparse=False)\n",
    "\n",
    "waveforms['si_cleaned_zeros'] = si.extract_waveforms(recordings[recording_name]['si_cleaned_zeros'], \n",
    "                             sorting, ms_before=10, ms_after=10, mode='memory',\n",
    "     n_jobs=10, allow_unfiltered=True, chunk_memory=\"10M\", overwrite=True, sparse=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Plotting waveform with the probe plot\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(13,9))\n",
    "si.plot_unit_templates(waveforms['si_filtered_medianremoved'], \n",
    "                       unit_ids=[waveform_id], same_axis=True, ax=axes[0], plot_legend=False)\n",
    "si.plot_unit_templates(waveforms['si_cleaned_zeros'], \n",
    "                       unit_ids=[waveform_id], same_axis=True, ax=axes[1], plot_legend=False)\n",
    "\n",
    "si.plot_unit_probe_map(waveforms['si_cleaned_zeros'], unit_ids=[waveform_id], with_channel_ids=True)\n",
    "\n",
    "\n",
    "## Plotting waveform electrode wise  \n",
    "\n",
    "unit_id = waveform_id\n",
    "\n",
    "colors = ['k', 'r', 'b']\n",
    "\n",
    "fig, axs = plt.subplots(4,1, figsize=(10,15))\n",
    "\n",
    "ax = axs[0]\n",
    "for i_key, key in enumerate(['si_filtered_medianremoved', 'si_cleaned_zeros']):\n",
    "    wfs= waveforms[key].get_waveforms(unit_id=unit_id)\n",
    "    for i_wf in range(wfs.shape[0]):\n",
    "        ax.plot(wfs[i_wf,:,elec], color = colors[i_key],\n",
    "                 label=key,\n",
    "                alpha=0.1)\n",
    "    ax.set_title(\"all waveforms\")\n",
    "        \n",
    "ax = axs[1]\n",
    "for i_key, key in enumerate(['si_filtered_medianremoved', 'si_cleaned_zeros']):\n",
    "    wfs= waveforms[key].get_waveforms(unit_id=unit_id)\n",
    "    ax.plot(np.median(wfs[:,:,elec],axis=0),\n",
    "           color = colors[i_key])\n",
    "    ax.set_title(\"medians\")\n",
    "        \n",
    "for i_key, key in enumerate(['si_filtered_medianremoved', 'si_cleaned_zeros',]):\n",
    "    ax = axs[i_key+2]\n",
    "\n",
    "    wfs= waveforms[key].get_waveforms(unit_id=unit_id)\n",
    "    for i_wf in range(wfs.shape[0]):\n",
    "        ax.plot(wfs[i_wf,:,elec], color = colors[i_key],\n",
    "                 label=key,\n",
    "                alpha=0.2)\n",
    "    ax.plot(np.median(wfs[:,:,elec],axis=0),\n",
    "           color = colors[i_key])\n",
    "\n",
    "    ax.set_title(\"waveforms and median\")\n",
    "\n",
    "plt.show(block=False)\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8764a60a",
   "metadata": {},
   "source": [
    "### Select recordings to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24baa3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : checkerboard \t --> visual\n",
      "1 : chirp \t --> visual\n",
      "2 : drifting_gratings \t --> visual\n",
      "3 : white_noise_1d \t --> visual\n",
      "4 : moving_bars \t --> visual\n",
      "5 : perturbed_moving_bar \t --> visual\n"
     ]
    }
   ],
   "source": [
    "#from colorama import Fore, Style\n",
    "\n",
    "skip_recording = []\n",
    "\n",
    "recording_list = []\n",
    "for rec_idx, recording_name in enumerate(recording_names):\n",
    "    \n",
    "    if rec_idx in skip_recording and (not print(Fore.RED+f\"{rec_idx} : {recording_name} --> /! SKIPPED /! \"+Style.RESET_ALL)):  continue\n",
    "    \n",
    "    print(f\"{rec_idx} : {recording_name}\",end=' ')\n",
    "    if \"si_cleaned_zeros\" in recordings[recording_name].keys():\n",
    "        recording_list += [recordings[recording_name]['si_cleaned_zeros']]\n",
    "        print('--> holo')\n",
    "    else:\n",
    "        print(\"\\t --> visual\")\n",
    "        recording_list += [recordings[recording_name]['si_filtered_medianremoved']]\n",
    "\n",
    "multirecording = si.concatenate_recordings(recording_list)\n",
    "multirecording = multirecording.set_probe(recording_list[0].get_probe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f572978",
   "metadata": {},
   "source": [
    "### RUN SORTING\n",
    "Choose your sorter to run and go have a coffee with a long paper or go home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f61bce0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NT': 'Batch size (if None it is automatically computed)',\n",
      " 'car': 'Enable or disable common reference',\n",
      " 'chunk_duration': 'Chunk duration in s if float or with units if str (e.g. '\n",
      "                   \"'1s', '500ms') (when saving to binary) - default global\",\n",
      " 'chunk_memory': \"Memory usage for each job (e.g. '100M', '1G') (when saving \"\n",
      "                 'to binary) - default global',\n",
      " 'chunk_size': 'Number of samples per chunk (when saving ti binary) - default '\n",
      "               'global',\n",
      " 'detect_threshold': 'Threshold for spike detection',\n",
      " 'freq_min': 'High-pass filter cutoff frequency',\n",
      " 'keep_good_only': \"If True only 'good' units are returned\",\n",
      " 'minFR': 'Minimum spike rate (Hz), if a cluster falls below this for too long '\n",
      "          'it gets removed',\n",
      " 'minfr_goodchannels': \"Minimum firing rate on a 'good' channel\",\n",
      " 'nPCs': 'Number of PCA dimensions',\n",
      " 'n_jobs': 'Number of jobs (when saving ti binary) - default -1 (all cores)',\n",
      " 'nfilt_factor': 'Max number of clusters per good channel (even temporary '\n",
      "                 'ones) 4',\n",
      " 'ntbuff': 'Samples of symmetrical buffer for whitening and spike detection',\n",
      " 'preclust_threshold': 'Threshold crossings for pre-clustering (in PCA '\n",
      "                       'projection space)',\n",
      " 'progress_bar': 'If True, progress bar is shown (when saving to binary) - '\n",
      "                 'default global',\n",
      " 'projection_threshold': 'Threshold on projections',\n",
      " 'sigmaMask': 'Spatial constant in um for computing residual variance of spike',\n",
      " 'total_memory': \"Total memory usage (e.g. '500M', '2G') (when saving to \"\n",
      "                 'binary) - default global',\n",
      " 'wave_length': 'size of the waveform extracted around each detected peak, '\n",
      "                '(Default 61, maximum 81)'}\n",
      "\n",
      "{'NT': None,\n",
      " 'car': True,\n",
      " 'chunk_duration': '1s',\n",
      " 'detect_threshold': 6,\n",
      " 'freq_min': 150,\n",
      " 'keep_good_only': False,\n",
      " 'minFR': 0.1,\n",
      " 'minfr_goodchannels': 0.1,\n",
      " 'nPCs': 3,\n",
      " 'n_jobs': 20,\n",
      " 'nfilt_factor': 4,\n",
      " 'ntbuff': 64,\n",
      " 'preclust_threshold': 8,\n",
      " 'progress_bar': True,\n",
      " 'projection_threshold': [10, 4],\n",
      " 'sigmaMask': 30,\n",
      " 'wave_length': 61}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(si.get_sorter_params_description('kilosort2'))\n",
    "print('')\n",
    "default_params = si.get_default_sorter_params('kilosort2')\n",
    "pprint.pprint(default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "116a137e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting container\n",
      "Installing spikeinterface==0.97.1 in spikeinterface/spyking-circus-base\n",
      "Running spykingcircus sorter inside spikeinterface/spyking-circus-base\n",
      "Stopping container\n",
      "SpykingCircusSortingExtractor: 8 units - 1 segments - 20.0kHz\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "##### Circus 1 dockerised #####\n",
    "###############################\n",
    "\n",
    "clustering_folder = os.path.join(params.sorting_directory,r'Circus_1/clustering')\n",
    "if not os.path.exists(clustering_folder): os.makedirs(clustering_folder)\n",
    "\n",
    "waveforms_directory = os.path.join(params.sorting_directory,r'Circus_1/waveforms')\n",
    "if not os.path.exists(waveforms_directory): os.makedirs(waveforms_directory)\n",
    "\n",
    "default_params = si.get_default_sorter_params('spykingcircus')\n",
    "custom_params = default_params.copy()\n",
    "custom_params['num_workers'] = int((cpu_count()/2)-2)\n",
    "custom_params['filter'] = False\n",
    "\n",
    "sorting = si.run_sorter('spykingcircus',\n",
    "    recording=test_recording,\n",
    "    output_folder=\"spyking_circus\",\n",
    "    **custom_params,\n",
    "    verbose=True,\n",
    "    docker_image=True)\n",
    "\n",
    "print(sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ba493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "##### Circus 1 #####\n",
    "####################\n",
    "\n",
    "clustering_folder = os.path.join(params.sorting_directory,r'Circus_1/clustering')\n",
    "if not os.path.exists(clustering_folder): os.makedirs(clustering_folder)\n",
    "\n",
    "waveforms_directory = os.path.join(params.sorting_directory,r'Circus_1/waveforms')\n",
    "if not os.path.exists(waveforms_directory): os.makedirs(waveforms_directory)\n",
    "\n",
    "\n",
    "# default_params = si.SpykingcircusSorter.default_params()\n",
    "default_params = si.get_default_sorter_params('spykingcircus')\n",
    "custom_params = default_params.copy()\n",
    "custom_params['num_workers'] = int((cpu_count()/2)-2)\n",
    "custom_params['filter'] = False\n",
    "\n",
    "\n",
    "sorting = si.run_sorter('spykingcircus',\n",
    "                        multirecording, \n",
    "                        clustering_folder,\n",
    "                       **custom_params,\n",
    "                        docker_image=True,\n",
    "                       verbose=True)\n",
    "\n",
    "print(f\"Waveforms extraction to {waveforms_directory}\")\n",
    "w = si.extract_waveforms(multirecording, sorting, waveforms_directory, dtype='float32', \n",
    "                         chunk_memory=\"10M\", overwrite=True, sparse=True, method='snr', threshold=1, n_jobs=int(cpu_count()/2))\n",
    "\n",
    "\n",
    "print(sorting)\n",
    "\n",
    "w = si.extract_waveforms(multirecording, sorting, waveforms_directory, dtype='float32', \n",
    "                         chunk_memory=\"10M\", overwrite=True, sparse=True, method='snr', threshold=1, n_jobs=int(cpu_count()/2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e179a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "##### Circus 2 #####\n",
    "####################\n",
    "\n",
    "clustering_folder = os.path.join(params.sorting_directory,r'Circus_2/clustering')\n",
    "if not os.path.exists(clustering_folder): os.makedirs(clustering_folder)\n",
    "\n",
    "waveforms_directory = os.path.join(params.sorting_directory,r'Circus_2/waveforms')\n",
    "if not os.path.exists(waveforms_directory): os.makedirs(waveforms_directory)\n",
    "\n",
    "nb_cpus = int(cpu_count()/2)\n",
    "\n",
    "default_params = si.Spykingcircus2Sorter.default_params()\n",
    "custom_params = default_params.copy()\n",
    "custom_params['job_kwargs'] = {'n_jobs': nb_cpus, 'verbose': True}\n",
    "custom_params['apply_preprocessing'] = False\n",
    "custom_params\n",
    "\n",
    "sorting = si.run_sorter('spykingcircus2',\n",
    "                        multirecording, \n",
    "                        clustering_folder,\n",
    "                       **custom_params,\n",
    "                       verbose=True)\n",
    "\n",
    "print(f\"Waveforms extraction to {waveforms_directory}\")\n",
    "w = si.extract_waveforms(multirecording, sorting, waveforms_directory, dtype='float32', \n",
    "                         chunk_memory=\"10M\", overwrite=True, sparse=True, method='snr', threshold=1, n_jobs=nb_cpus)\n",
    "\n",
    "\n",
    "print(sorting)\n",
    "\n",
    "w = si.extract_waveforms(multirecording, sorting, waveforms_directory, dtype='float32', \n",
    "                         chunk_memory=\"10M\", overwrite=True, sparse=True, method='snr', threshold=1, n_jobs=nb_cpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9b524",
   "metadata": {},
   "source": [
    "### Sorting Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc51272",
   "metadata": {},
   "source": [
    "Work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc39bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then run 3 spike sorters and compare their outputs.\n",
    "sortings = {\n",
    "    \"spykingcircus1\"  : si.read_sorter_folder(os.path.join(params.sorting_directory,r'Circus_1/clustering')),\n",
    "    \"spykingcircus2\"  : si.read_sorter_folder(os.path.join(params.sorting_directory,r'Circus_2/clustering')),\n",
    "    \"yass\" : si.read_sorter_folder(os.path.join(params.sorting_directory,r'YASS/clustering')),\n",
    "    \"kilosort2\"   : si.read_sorter_folder(os.path.join(params.sorting_directory,r'kilosort2/clustering'))\n",
    "    }\n",
    "\n",
    "# Compare multiple spike sorter outputs\n",
    "mcmp = si.compare_multiple_sorters(\n",
    "    sorting_list=[item[1] for item in sorting.items]\n",
    "    name_list=[key for key in sortings.keys()],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# The multiple sorters comparison internally computes pairwise comparisons,\n",
    "# that can be accessed as follows:\n",
    "print(mcmp.comparisons[('spykingcircus1', 'spykingcircus2')].sorting1, mcmp.comparisons[('spykingcircus1', 'spykingcircus2')].sorting2)\n",
    "print(mcmp.comparisons[('spykingcircus1', 'spykingcircus2')].get_matching())\n",
    "\n",
    "print(mcmp.comparisons[('spykingcircus1', 'kilosort2')].sorting1, mcmp.comparisons[('spykingcircus1', 'kilosort2')].sorting2)\n",
    "print(mcmp.comparisons[('spykingcircus1', 'kilosort2')].get_matching())\n",
    "\n",
    "# The global multi comparison can be visualized with this graph\n",
    "sw.plot_multicomp_graph(mcmp)\n",
    "\n",
    "# Consensus-based method\n",
    "\n",
    "agr_3 = mcmp.get_agreement_sorting(minimum_agreement_count=3)\n",
    "print('Units in agreement for all three sorters: ', agr_3.get_unit_ids())\n",
    "\n",
    "agr_2 = mcmp.get_agreement_sorting(minimum_agreement_count=2)\n",
    "print('Units in agreement for at least two sorters: ', agr_2.get_unit_ids())\n",
    "\n",
    "agr_all = mcmp.get_agreement_sorting()\n",
    "\n",
    "# The unit index of the different sorters can also be retrieved from the\n",
    "# agreement sorting object (:code:`agr_3`) property :code:`sorter_unit_ids`.\n",
    "\n",
    "print(agr_3.get_property('unit_ids'))\n",
    "\n",
    "print(agr_3.get_unit_ids())\n",
    "# take one unit in agreement\n",
    "unit_id0 = agr_3.get_unit_ids()[0]\n",
    "sorter_unit_ids = agr_3.get_property('unit_ids')[0]\n",
    "print(unit_id0, ':', sorter_unit_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43445ea3",
   "metadata": {},
   "source": [
    "### Export to phy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Input\n",
    "Give the path to your sorting folder (i.e. kilosort, circus1, circus2, ...)\n",
    "\"\"\"\n",
    "\n",
    "clustering_folder = os.path.join(params.sorting_directory,r'Circus_1/clustering')\n",
    "\n",
    "waveforms_directory = os.path.join(params.sorting_directory,r'Circus_1/waveforms')\n",
    "\n",
    "\"\"\"\n",
    "    Params\n",
    "\"\"\"\n",
    "\n",
    "copy_binary = True   #Set to false for it to be much faster but you will lose spikes raw traces on the waveform view\n",
    "                      #There is currently an error in the spikeinterface code with an uninitalized variable when exporting without raw\n",
    "                      #It has been reported and should be fixed in the futur. \n",
    "                      #### Meanwhile, juste keep True here ####\n",
    "\n",
    "phy_directory = params.phy_directory\n",
    "\n",
    "nb_cpus = int(cpu_count()/2)  #This should be at maximum the number of real cores you have in your cpu (intel's cpu shows hyperthreaded number of cores)\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "\n",
    "sorting = si.read_sorter_folder(clustering_folder)\n",
    "print(sorting)\n",
    "try:\n",
    "    \n",
    "    w = si.load_waveforms(waveforms_directory)\n",
    "    print(f\"Waveforms read from {waveforms_directory}\")\n",
    "except:\n",
    "    print(f\"Waveforms extraction to {waveforms_directory}\")\n",
    "    w = si.extract_waveforms(multirecording, sorting, waveforms_directory, dtype='float32', \n",
    "                         chunk_memory=\"10M\", overwrite=True, sparse=True, method='snr', threshold=1, n_jobs=nb_cpus)\n",
    "\n",
    "print(f\"Exportion to phy format at {phy_directory}\")\n",
    "si.export_to_phy(w, phy_directory,\n",
    "                 copy_binary = copy_binary,\n",
    "                 compute_pc_features=False,\n",
    "                 compute_amplitudes=True,\n",
    "                 remove_if_exists=True,\n",
    "                 verbose=True,\n",
    "                 n_jobs=nb_cpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286b2ff",
   "metadata": {},
   "source": [
    "### Cell 6 : Creating all clusters rasters plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd265816",
   "metadata": {},
   "source": [
    "#### <center>REQUIRES CELL 1 RUN</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fb3f36",
   "metadata": {},
   "source": [
    "Run after automatic sorting to help with manual sorting. Saves all automatic clusters' rasters on the repeated checherboard in the phy directory. You can run this several times during sorting to make new clusters rasters. Can take few sec per cluster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd5fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Variable\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "#length of each sequence composed of half repeated sequence and half random sequence\n",
    "\n",
    "nb_frames_by_sequence = params.nb_frames_by_sequence\n",
    "\n",
    "# Name of your experiment\n",
    "exp = params.exp\n",
    "\n",
    "#Path to the folder with the phy output\n",
    "phy_directory = params.phy_directory\n",
    "\n",
    "#Path to raw recording files\n",
    "recoding_directory = params.recording_directory\n",
    "\n",
    "#Frequency of sampling of the mea\n",
    "fs = params.fs\n",
    "\n",
    "\"\"\"\n",
    "    Input\n",
    "\"\"\"\n",
    "#Number of the checkerboard recording of choice (start from zero)\n",
    "print(*['{} : {}'.format(i,recording_name) for i, recording_name in enumerate(recordings.keys())], sep=\"\\n\")\n",
    "check_recording_number = int(input(\"\\nSelect Checkerboard recording : \"))\n",
    "checkerboard_name = recording_names[check_recording_number]\n",
    "\n",
    "#Checkerboard frequency in Hz\n",
    "\n",
    "stimulus_frequency = int(input(\"\\nEnter Checkerboard frequency of the recording '{}.raw' : \".format(checkerboard_name)))\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "###################################\n",
    "#### Loading phy clusters info ####\n",
    "###################################\n",
    "\n",
    "\n",
    "\n",
    "rec_onsets = recording_onsets(recording_names, path = recording_directory)  \n",
    "\n",
    "# Get cells index and number\n",
    "cluster_number , good_clusters = extract_cluster_groups(phy_directory)\n",
    "\n",
    "# Extract the spike times from the spike sorting files. This can take a few minutes.\n",
    "print('Spike extraction: ')\n",
    "all_spike_times = extract_all_spike_times_from_phy(phy_directory)\n",
    "\n",
    "# create a dictionary with another dictionary for each cluster\n",
    "all_neurons_data = split_spikes_by_recording(all_spike_times, cluster_number, rec_onsets)\n",
    "\n",
    "\n",
    "#############################\n",
    "#### Making raster plots ####\n",
    "#############################\n",
    "\n",
    "checkerboard_name = recording_names[check_recording_number]\n",
    "\n",
    "checkerboard_spikes = get_recording_spikes(checkerboard_name, all_neurons_data)\n",
    "\n",
    "trig_data = load_obj(os.path.normpath(os.path.join(params.triggers_directory,'{}_{}_triggers.pkl'.format(exp,checkerboard_name))))\n",
    "triggers = trig_data['indices']/fs\n",
    "raster_data = {}\n",
    "\n",
    "print('Building Raster plots : ')\n",
    "for (cell_nb, spike_times) in tqdm(checkerboard_spikes.items()):\n",
    "    # Align triggers and spike times\n",
    "    aligned_triggers, aligned_spike_times = align_triggers_spikes(triggers, spike_times)\n",
    "    \n",
    "    # Get rasters on repeated sequence\n",
    "    raster_data[cell_nb] = build_rasters(aligned_spike_times, aligned_triggers, stim_frequency = stimulus_frequency)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Saving\n",
    "\"\"\"\n",
    "\n",
    "#Save all clusters rasters plots    \n",
    "fig_directory = os.path.normpath(os.path.join(phy_directory,r'clusters_rasters_{}'.format(check_recording_number)))\n",
    "if not os.path.isdir(fig_directory): os.makedirs(fig_directory)\n",
    "\n",
    "    \n",
    "print(\"Saving rasters plots of all clusters :\")\n",
    "for cell_nb in tqdm(raster_data.keys()):\n",
    "    fig, axs = plt.subplots(nrows = 2,ncols = 1, sharex=True, gridspec_kw={'height_ratios': [3, 1]}, figsize=(10,10))\n",
    "\n",
    "    plt.suptitle(f'Cell {cell_nb}')\n",
    "\n",
    "    ax_rast = axs[0]\n",
    "    ax_rast.eventplot(raster_data[cell_nb][\"spike_trains\"])\n",
    "    ax_rast.set(title = \"Raster plot\", ylabel='N Repetitions')\n",
    "\n",
    "    ax_psth = axs[1]\n",
    "    width = (raster_data[cell_nb][\"repeated_sequences_times\"][0][0]/600)\n",
    "    ax_psth.bar(np.linspace(0,raster_data[cell_nb][\"repeated_sequences_times\"][0][0],int(nb_frames_by_sequence/2))+width/2, raster_data[cell_nb][\"psth\"], width=1.3*width)\n",
    "    ax_psth.set(xlabel='Time in sec', ylabel='Firing rate (spikes/s)')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig_file = os.path.normpath(os.path.join(fig_directory,f'Cluster_{cell_nb}.png'))\n",
    "    plt.savefig(fig_file, dpi=fig.dpi)\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "\"\"\"\n",
    "    Output\n",
    "    \n",
    "    Save :\n",
    "    \n",
    "    \"\"{phy_directory}/clusters_rasters/Cluster_{Cluster_number}.png\" for each found clusters in phy's files\n",
    "\"\"\"    \n",
    "\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5828e3db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = f\"phy template-gui {params.phy_directory}/params.py\"\n",
    "\n",
    "!env QTWEBENGINE_CHROMIUM_FLAGS=\"--single-process\" {out}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02514cc0",
   "metadata": {},
   "source": [
    "# <center>/!\\/!\\/!\\ Run this after sorting /!\\/!\\/!\\ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a934a5bd",
   "metadata": {},
   "source": [
    "### Cell 7 : Extract data per neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0604a2df",
   "metadata": {},
   "source": [
    "#### <center>REQUIRES CELL 1 RUN</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10aa831",
   "metadata": {},
   "source": [
    "Extract all data from phy numpy variables. Create&save a dictionnary containg spikes times in sec for each neuron splited by recording. Depending on your experiment, this can take severeal minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7587d813",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 good clusters (151 clusters in total)\n",
      "\n",
      "Spike extraction: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589c48663faf40f7bf71866f97767d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3933362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Spike division in recordings per neuron:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7058cc6802140d3bd1f64bfb5c8f913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t\t------ End Of Cell ------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Variable\n",
    "    \n",
    "    You will find here all variables used in this notebook cell. They should always refere to your 'params.py' file\n",
    "    except if you want to manually change some variable only for this run (i.e. debugging). You may have to add those\n",
    "    variable into the function you want to adapt as only the minimal amount of var are currently given to functions as inputs.\n",
    "\"\"\"\n",
    "\n",
    "# Name of your experiment\n",
    "exp = params.exp\n",
    "\n",
    "#Path to the folder with the phy output\n",
    "phy_directory = params.phy_directory\n",
    "\n",
    "#Path to where data should be saved\n",
    "output_directory = params.output_directory\n",
    "\n",
    "#Path to rax recording files\n",
    "recoding_directory = params.recording_directory\n",
    "\n",
    "#Frequency of sampling of the mea\n",
    "fs = params.fs\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Processing\n",
    "\"\"\"\n",
    "\n",
    "rec_onsets    = recording_onsets(recording_names, path = recording_directory)  \n",
    "\n",
    "# Get cells index and number\n",
    "cluster_number , good_clusters = extract_cluster_groups(phy_directory)\n",
    "print(\"There are {} good clusters ({} clusters in total)\\n\".format(len(good_clusters), len(cluster_number)))\n",
    "\n",
    "\n",
    "# Extract the spike times from the spike sorting files. This can take a few minutes.\n",
    "print('Spike extraction: ')\n",
    "all_spike_times = extract_all_spike_times_from_phy(phy_directory)\n",
    "\n",
    "print('\\n')\n",
    "print('Spike division in recordings per neuron:')\n",
    "# create a dictionary with another dictionary for each good cluster\n",
    "good_data = split_spikes_by_recording(all_spike_times, good_clusters, rec_onsets)\n",
    "\n",
    "\n",
    "# Save the spike data. This can take a few minutes.\n",
    "good_data_file_name = os.path.join(output_directory,r'{}_fullexp_neurons_data.pkl'.format(exp))\n",
    "save_obj(good_data,good_data_file_name)\n",
    "\n",
    "\"\"\"\n",
    "    Output\n",
    "    \n",
    "    data (dict) : key 'cluster_id' --> (dict) key 'recording_name' --> This neuron & this recording spikes times in sec\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print('\\n\\t\\t\\t------ End Of Cell ------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f559b9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(os.path.join(params.phy_directory, 'spike_clusters.npy'))\n",
    "fold='/media/guiglaz/Guilhem_01/deby/20220722_VIP.Project_18betaG/sorting/recording_0/recording_0.GUI'\n",
    "b = np.load(os.path.join(fold, 'spike_clusters.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "697f824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(os.path.join(params.phy_directory, 'spike_times.npy'))\n",
    "fold='/media/guiglaz/Guilhem_01/deby/20220722_VIP.Project_18betaG/sorting/recording_0/recording_0.GUI'\n",
    "b = np.load(os.path.join(fold, 'spike_times.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e97f0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3933362, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
